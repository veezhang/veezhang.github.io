<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【golang源码分析】之GPM调度]]></title>
    <url>%2F2020%2F02%2F02%2F%E3%80%90golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%E4%B9%8BGPM%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;上一篇 【golang源码分析】之GPM概述 ，我们介绍 GPM 的一些基础概念，这里将是重点，梳理 GMP 的调度流程。其实在 【golang源码分析】之启动追踪 中以及梳理了一下启动流程，涉及到的地方，这里会简要的过一下。初始化程序的入口12345678910// src/runtime/rt0_linux_amd64.s// linux amd64 系统的启动函数TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8 JMP _rt0_amd64(SB) // 跳转到_rt0_amd64函数， 在 asm_amd64.s 中。// src/runtime/asm_amd64.sTEXT _rt0_amd64(SB),NOSPLIT,$-8 MOVQ 0(SP), DI // argc // 设置参数argc LEAQ 8(SP), SI // argv // 设置参数argv JMP runtime·rt0_go(SB) // 跳转到runtime·rt0_go 然后会调用 runtime·rt0_go 来初始化，是非常核心的代码。 初始化 g0&emsp;&emsp;g0 的主要作用是提供一个栈供 runtime 代码执行，因此这里主要对 g0 的几个与栈有关的成员进行了初始化。 1234567891011121314151617// src/runtime/asm_amd64.sTEXT runtime·rt0_go(SB),NOSPLIT,$0 ... // create istack out of the given (operating system) stack. // _cgo_init may update stackguard. // 从给定（操作系统）栈中创建 istack 。 _cgo_init 可能更新 stackguard // runtime.g0 位于 runtime/proc.go // 初始化 g0，g0 的栈实际上就是 linux 分配的栈，大约 64k。 MOVQ $runtime·g0(SB), DI // DI = runtime·g0 LEAQ (-64*1024+104)(SP), BX // BX = SP-64*1024+104 MOVQ BX, g_stackguard0(DI) // g0.stackguard0 = SP-64*1024+104 MOVQ BX, g_stackguard1(DI) // g0.stackguard1 = g0.stackguard0 MOVQ BX, (g_stack+stack_lo)(DI) // g0.stack.lo = g0.stackguard0 MOVQ SP, (g_stack+stack_hi)(DI) // g0.stack.hi = SP ... 主线程绑定 m01234567891011121314151617181920212223// src/runtime/asm_amd64.sTEXT runtime·rt0_go(SB),NOSPLIT,$0 ... // 设置tls， Thread Local Storage LEAQ runtime·m0+m_tls(SB), DI // DI = m0.tls ，这个会在 runtime·settls 中使用 CALL runtime·settls(SB) // 调用 runtime·settls ...// set the per-goroutine and per-mach "registers" // 将 g0 放到 tls 里，这里实际上就是 m0.tls get_tls(BX) // 等价于 MOVQ TLS, BX 。 从 TLS 起始移动 8 byte 值到 BX 寄存器，获取 fs 段基地址并放入 BX 寄存器，其实就是 m0.tls[1] 的地址 LEAQ runtime·g0(SB), CX // CX=g0 MOVQ CX, g(BX) // 等价于 MOVQ CX， 0(BX)(TLS*1), 也就是m0.tls[0] = g0 LEAQ runtime·m0(SB), AX // AX=m0 // save m-&gt;g0 = g0 MOVQ CX, m_g0(AX) // m0.g0 = g0 // save m0 to g0-&gt;m MOVQ AX, g_m(CX) // g0.m = m0 ... &emsp;&emsp;上面的代码首先把 g0 的地址放入主线程的 TLS 中，然后通过 m0.g0 = &amp;g0, g0.m = &amp;m0 把 m0 和 g0 绑定在一起，这样，之后在主线程中通过 get_tls 可以获取到 g0 ，通过 g0 的 m 成员又可以找到 m0 ，于是这里就实现了m0和g0与主线程之间的关联。 12345678// src/runtime/asm_amd64.sTEXT runtime·rt0_go(SB),NOSPLIT,$0 ... CALL runtime·osinit(SB) // 初始化 os ，在 os_linux.go CALL runtime·schedinit(SB) // 初始化 sched ，在 proc.go ... &emsp;&emsp;osinit 主要是初始化 ncpu ， schedinit 是核心的初始化。 初始化m0123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// src/runtime/proc.go// The bootstrap sequence is://// call osinit// call schedinit// make &amp; queue new G// call runtime·mstart//// The new G calls runtime·main.// 启动顺序// 调用 osinit// 调用 schedinit// make &amp; queue new G// 调用 runtime·mstart// 创建 G 的调用 runtime·main.//// 初始化sched, 核心部分func schedinit() &#123; ... _g_ := getg() // _g_ = g0 if raceenabled &#123; _g_.racectx, raceprocctx0 = raceinit() &#125; // 最大系统线程数量（即 M），参考标准库 runtime/debug.SetMaxThreads sched.maxmcount = 10000 ... mcommoninit(_g_.m) // 初始化当前 M ... // 网络的上次轮询时间 sched.lastpoll = uint64(nanotime()) // 设置procs， 根据cpu核数和环境变量GOMAXPROCS， 优先环境变量 procs := ncpu if n, ok := atoi32(gogetenv("GOMAXPROCS")); ok &amp;&amp; n &gt; 0 &#123; procs = n &#125; // 调整 P 的数量，这时所有 P 均为新建的 P，因此不能返回有本地任务的 P if procresize(procs) != nil &#123; throw("unknown runnable goroutine during bootstrap") &#125; ...&#125; &emsp;&emsp;g0 的地址已经被设置到了 TLS 之中，_g_ := getg() 获取的为 g0 ，mcommoninit(_g_.m) 即为初始化 m0 ，这里我们先关注下 mcommoninit 函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// src/runtime/proc.go// 通用初始化 Mfunc mcommoninit(mp *m) &#123; _g_ := getg() // g0 stack won't make sense for user (and is not necessary unwindable). // 检查当前 g 是否是 g0，g0 栈对用户而言是没有意义的（且不是不可避免的） if _g_ != _g_.m.g0 &#123; callers(1, mp.createstack[:]) &#125; // 锁住调度器 lock(&amp;sched.lock) // 确保线程数量不会太多而溢出 if sched.mnext+1 &lt; sched.mnext &#123; throw("runtime: thread ID overflow") &#125; // mnext 表示当前 m 的数量，还表示下一个 m 的 id mp.id = sched.mnext // 增加 m 的数量 sched.mnext++ // 检测 m 的数量 checkmcount() // 用于 fastrand 快速取随机数 mp.fastrand[0] = 1597334677 * uint32(mp.id) mp.fastrand[1] = uint32(cputicks()) if mp.fastrand[0]|mp.fastrand[1] == 0 &#123; mp.fastrand[1] = 1 &#125; // 初始化 gsignal，用于处理 m 上的信号。 mpreinit(mp) // gsignal 的运行栈边界处理 if mp.gsignal != nil &#123; mp.gsignal.stackguard1 = mp.gsignal.stack.lo + _StackGuard &#125; // Add to allm so garbage collector doesn't free g-&gt;m // when it is just in a register or thread-local storage. // 添加到 allm 中，从而当它刚保存到寄存器或本地线程存储时候 GC 不会释放 g-&gt;m // 每一次调用都会将 allm 给 alllink，给完之后自身被 mp 替换，在下一次的时候又给 alllink ，从而形成链表 mp.alllink = allm // NumCgoCall() iterates over allm w/o schedlock, // so we need to publish it safely. // NumCgoCall() 会在没有使用 schedlock 时遍历 allm，因此我们需要安全的修改。 // 等价于 allm = mp atomicstorep(unsafe.Pointer(&amp;allm), unsafe.Pointer(mp)) // m 的通用初始化完成，解锁调度器 unlock(&amp;sched.lock) // Allocate memory to hold a cgo traceback if the cgo call crashes. // 分配内存来保存当 cgo 调用崩溃时候的回溯 if iscgo || GOOS == "solaris" || GOOS == "windows" &#123; mp.cgoCallers = new(cgoCallers) &#125;&#125; &emsp;&emsp;mcommoninit 并未对 m0 做什么关于调度相关的初始化，只是将 m0 放入全局链表 allm 之中。 初始化allp&emsp;&emsp;然后我们在关注 procresize 函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281// src/runtime/proc.go// Change number of processors. The world is stopped, sched is locked.// gcworkbufs are not being modified by either the GC or// the write barrier code.// Returns list of Ps with local work, they need to be scheduled by the caller.// 修改 P 的数量，此时所有工作均被停止 STW，sched 被锁定。 gcworkbufs 既不会被 GC 修改，也不会被 write barrier 修改。// 返回带有 local work 的 P 列表，他们需要被调用方调度。func procresize(nprocs int32) *p &#123; // 获取之前的 P 个数 old := gomaxprocs // 边界检查 if old &lt; 0 || nprocs &lt;= 0 &#123; throw("procresize: invalid arg") &#125; // trace 相关 if trace.enabled &#123; traceGomaxprocs(nprocs) &#125; // update statistics // 更新统计信息，记录此次修改 gomaxprocs 的时间 now := nanotime() if sched.procresizetime != 0 &#123; sched.totaltime += int64(old) * (now - sched.procresizetime) &#125; sched.procresizetime = now // Grow allp if necessary. // 必要时增加 allp // 这个时候本质上是在检查用户代码是否有调用过 runtime.MAXGOPROCS 调整 p 的数量。 // 此处多一步检查是为了避免内部的锁，如果 nprocs 明显小于 allp 的可见数量，则不需要进行加锁 if nprocs &gt; int32(len(allp)) &#123; // Synchronize with retake, which could be running // concurrently since it doesn't run on a P. // 此处与 retake 同步，它可以同时运行，因为它不会在 P 上运行。 lock(&amp;allpLock) if nprocs &lt;= int32(cap(allp)) &#123; // 如果 allp 容量足够，去切片就好了 allp = allp[:nprocs] &#125; else &#123; // 否则 allp 容量不够，重新申请 nallp := make([]*p, nprocs) // Copy everything up to allp's cap so we // never lose old allocated Ps. // 将所有内容复制到 allp 的上，这样我们就永远不会丢失旧分配的P 。 copy(nallp, allp[:cap(allp)]) allp = nallp &#125; unlock(&amp;allpLock) &#125; // initialize new P's // 初始化新的 P for i := int32(0); i &lt; nprocs; i++ &#123; pp := allp[i] // 如果 p 是新创建的(新创建的 p 在数组中为 nil)，则申请新的 P 对象 if pp == nil &#123; pp = new(p) pp.id = i // p 的 id 就是它在 allp 中的索引 pp.status = _Pgcstop // 新创建的 p 处于 _Pgcstop 状态 pp.sudogcache = pp.sudogbuf[:0] for i := range pp.deferpool &#123; pp.deferpool[i] = pp.deferpoolbuf[i][:0] &#125; pp.wbBuf.reset() atomicstorep(unsafe.Pointer(&amp;allp[i]), unsafe.Pointer(pp)) &#125; // 为 P 分配 cache 对象 if pp.mcache == nil &#123; // 如果 old == 0 且 i == 0 说明这是引导阶段初始化第一个 p 。schedinit 中 mallocinit 有初始化一个 mcache if old == 0 &amp;&amp; i == 0 &#123; // 确认当前 g 的 m 的 mcache 非空 if getg().m.mcache == nil &#123; throw("missing mcache?") &#125; pp.mcache = getg().m.mcache // bootstrap &#125; else &#123; pp.mcache = allocmcache() &#125; &#125; // 如果 启动了 race 并且 racectx 为 0，则新建 if raceenabled &amp;&amp; pp.racectx == 0 &#123; // 如果 old == 0 且 i == 0 说明这是引导阶段初始化第一个 p 。 schedinit 中有初始化一个 raceproccreate if old == 0 &amp;&amp; i == 0 &#123; pp.racectx = raceprocctx0 raceprocctx0 = 0 // bootstrap &#125; else &#123; pp.racectx = raceproccreate() &#125; &#125; &#125; // free unused P's // 释放不用的 P for i := nprocs; i &lt; old; i++ &#123; p := allp[i] if trace.enabled &amp;&amp; p == getg().m.p.ptr() &#123; // moving to p[0], pretend that we were descheduled // and then scheduled again to keep the trace sane. // 移至 p[0] ，假装我们已被调度，然后再次调度以保持跟踪正常。 traceGoSched() traceProcStop(p) &#125; // move all runnable goroutines to the global queue // 将所有的 runnable goroutines 移动到全局队列 sched.runq for p.runqhead != p.runqtail &#123; // pop from tail of local queue // 从本地队列的尾部 pop p.runqtail-- gp := p.runq[p.runqtail%uint32(len(p.runq))].ptr() // push onto head of global queue // push 到全局队列的头部 globrunqputhead(gp) &#125; // 如果 runnext 不为 0，也加入到全局队列 sched.runq if p.runnext != 0 &#123; globrunqputhead(p.runnext.ptr()) p.runnext = 0 &#125; // if there's a background worker, make it runnable and put // it on the global queue so it can clean itself up // 如果存在 gc 后台 worker，则让其 runnable 并将其放到全局队列中从而可以让其对自身进行清理 if gp := p.gcBgMarkWorker.ptr(); gp != nil &#123; casgstatus(gp, _Gwaiting, _Grunnable) if trace.enabled &#123; traceGoUnpark(gp, 0) &#125; globrunqput(gp) // This assignment doesn't race because the // world is stopped. // 此赋值不会发生竞争，因为此时已经 STW p.gcBgMarkWorker.set(nil) &#125; // Flush p's write barrier buffer. // 刷新 p 的写屏障缓存 if gcphase != _GCoff &#123; wbBufFlush1(p) p.gcw.dispose() &#125; // 设置 sudogbuf for i := range p.sudogbuf &#123; p.sudogbuf[i] = nil &#125; p.sudogcache = p.sudogbuf[:0] for i := range p.deferpool &#123; for j := range p.deferpoolbuf[i] &#123; p.deferpoolbuf[i][j] = nil &#125; p.deferpool[i] = p.deferpoolbuf[i][:0] &#125; // 释放当前 P 绑定的 mcache freemcache(p.mcache) p.mcache = nil // 将当前 P 的 G 复链转移到全局 gfpurge(p) traceProcFree(p) if raceenabled &#123; raceprocdestroy(p.racectx) p.racectx = 0 &#125; p.gcAssistTime = 0 p.status = _Pdead // can't free P itself because it can be referenced by an M in syscall // 不能释放 P 本身，因为它可能被系统调用的 M 引用。 &#125; // Trim allp. // 修剪 allp if int32(len(allp)) != nprocs &#123; lock(&amp;allpLock) allp = allp[:nprocs] unlock(&amp;allpLock) &#125; _g_ := getg() if _g_.m.p != 0 &amp;&amp; _g_.m.p.ptr().id &lt; nprocs &#123; // 当前的 P 不需要被释放 // continue to use the current P // 继续使用当前 P _g_.m.p.ptr().status = _Prunning _g_.m.p.ptr().mcache.prepareForSweep() &#125; else &#123; // release the current P and acquire allp[0] // 释放当前 P，然后获取 allp[0] // p 和 m 解绑 if _g_.m.p != 0 &#123; _g_.m.p.ptr().m = 0 &#125; _g_.m.p = 0 _g_.m.mcache = nil // 更换到 allp[0] p := allp[0] p.m = 0 p.status = _Pidle acquirep(p) // 直接将 allp[0] 绑定到当前的 M if trace.enabled &#123; traceGoStart() &#125; &#125; var runnablePs *p for i := nprocs - 1; i &gt;= 0; i-- &#123; p := allp[i] // 确保不是当前正在使用的 P if _g_.m.p.ptr() == p &#123; continue &#125; // 将 p 设为 _Pidle p.status = _Pidle // 本地任务列表是否为空 if runqempty(p) &#123; // 放入 idle 链表 pidleput(p) &#125; else &#123; // 如果有本地任务，则为其绑定一个 M（不一定能获取到） p.m.set(mget()) // 第一个循环为 nil，后续则为上一个 p，此处即为构建可运行的 p 链表 p.link.set(runnablePs) runnablePs = p &#125; &#125; stealOrder.reset(uint32(nprocs)) var int32p *int32 = &amp;gomaxprocs // make compiler check that gomaxprocs is an int32 // 让编译器检查 gomaxprocs 是 int32 类型 atomic.Store((*uint32)(unsafe.Pointer(int32p)), uint32(nprocs)) // 让编译器检查 gomaxprocs 是 int32 类型 return runnablePs&#125;// Associate p and the current m.//// This function is allowed to have write barriers even if the caller// isn't because it immediately acquires _p_.// 将 p 关联到当前的 m 。因为该函数会立即 acquire P，因此即使调用方不允许 write barrier，此函数仍然允许 write barrier。////go:yeswritebarrierrecfunc acquirep(_p_ *p) &#123; // Do the part that isn't allowed to have write barriers. // 此处不允许 write barrier 。关联了当前的 M 到 P 上。 wirep(_p_) // Have p; write barriers now allowed. // 已经获取了 p，因此之后允许 write barrier // Perform deferred mcache flush before this P can allocate // from a potentially stale mcache. // 在此 P 可以从可能过时的 mcache 分配前执行延迟的 mcache flush _p_.mcache.prepareForSweep() if trace.enabled &#123; traceProcStart() &#125;&#125;// wirep is the first step of acquirep, which actually associates the// current M to _p_. This is broken out so we can disallow write// barriers for this part, since we don't yet have a P.// wirep 为 acquirep 的实际获取 p 的第一步，它关联了当前的 M 到 P 上。 我们在这部分使用 write barriers 被打破了，因为我们还没有P。////go:nowritebarrierrec//go:nosplitfunc wirep(_p_ *p) &#123; _g_ := getg() // 如果当前的 m 已经关联了 p if _g_.m.p != 0 || _g_.m.mcache != nil &#123; throw("wirep: already in go") &#125; // 如果 _p_ 已经关联了 m ， 且 _p_ 的状态不是 _Pidle if _p_.m != 0 || _p_.status != _Pidle &#123; id := int64(0) if _p_.m != 0 &#123; id = _p_.m.ptr().id &#125; print("wirep: p-&gt;m=", _p_.m, "(", id, ") p-&gt;status=", _p_.status, "\n") throw("wirep: invalid p state") &#125; // 关联当前 m 和 _p_ ， 并设置 _p_ 为 _Prunning _g_.m.mcache = _p_.mcache // 使用 p 的 mcache _g_.m.p.set(_p_) // 将 p 关联到到 m _p_.m.set(_g_.m) // 将 m 关联到到 p _p_.status = _Prunning // 设置 _Prunning&#125; &emsp;&emsp;这个函数看起来比较长，其实并不复杂，主要流程是： 初始化全局变量 allp ， allp = make([]*p, nprocs) ，可能存在复用和扩增之前的 allp ，由于这里是第一次初始化，所以仅仅是初始化。 初始化所有新的 P ， 包括 status(-&gt;_Pgcstop) ， sudogbuf , mcache 等。 释放不用的 P ，包括本地运行队列， sudogbuf ， mcache ， status(-&gt;_Pdead) 等。 如果有当前的 P 并且这个 P 不是被释放的，则设置状态改为 _Prunning ；否则设置为 _Pidle ， 然后调用 acquirep -&gt;wirep 又会将其状态设置为 _Prunning ，并且设置其 mcache 。由于这里还没初始化 m0-&gt;p ，所以会走后面的逻辑，此时 m0 和 allp[0] 绑定。 把其它的 P 设置为 _Pidle 状态并根据情况放置到 pidle 空闲队列之中，或者返回可运行的 P 。这里肯定是将其它所有的设置为 _Pidle 状态。 &emsp;&emsp;至此，m0, g0 和 allp 都初始化完成了，那么怎么启动我们的 main 函数呢？ schedinit 中貌似并没有相关的代码。我们返回来看 runtime·rt0_go 后面做了什么事情。 创建main goroutine123456789101112131415161718// src/runtime/asm_amd64.sTEXT runtime·rt0_go(SB),NOSPLIT,$0 ... // create a new goroutine to start program // 创建 goroutine 并加入到等待队列，该 goroutine 执行 runtime.mainPC 所指向的函数 MOVQ $runtime·mainPC(SB), AX // entry// 入口函数 在 proc.go 中 PUSHQ AX // 压栈，设置参数 runtime·newproc 的 fn PUSHQ $0 // arg size // 压栈，设置参数 runtime·newproc 的 siz CALL runtime·newproc(SB) // 调用 runtime·newproc ，在 proc.go 函数原型： func newproc(siz int32, fn *funcval) POPQ AX // 弹出 PUSHQ $0 POPQ AX // 弹出 PUSHQ AX ...// 声明全局的变量 mainPC 为 runtime.main 函数的地址，该变量为 read onlyDATA runtime·mainPC+0(SB)/8,$runtime·main(SB)GLOBL runtime·mainPC(SB),RODATA,$8 &emsp;&emsp;上面我们可以看到，设置 runtime·mainPC 函数，然后调用 runtime·newproc 来创建 g ，注意此处的 runtime·mainPC 还不是我们写代码的 main 函数，而是 runtime 中定义的 main 函数，后面会讲到，这里首先看 newproc 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128// src/runtime/proc.go//go:nosplit// 创建 G 运行 fn , 参数大小为 siz 。把 G 放到等待队列。编译器会将 go 语句转化为该调用。// 这时不能将栈进行分段，因为它假设了参数在 &amp;fn 之后顺序有效；如果 stack 进行了分段则他们不无法被拷贝。func newproc(siz int32, fn *funcval) &#123; // add 是一个指针运算，跳过函数指针，把栈上的参数起始地址找到，见 runtime2.go 中的 funcval 类型 argp := add(unsafe.Pointer(&amp;fn), sys.PtrSize) gp := getg() // 获取调用方 PC 寄存器值 pc := getcallerpc() // 用 g0 系统栈创建 goroutine 对象。传递的参数包括 fn 函数入口地址, argp 参数起始地址, siz 参数长度, gp(g0)，调用方 pc(goroutine) systemstack(func() &#123; newproc1(fn, (*uint8)(argp), siz, gp, pc) &#125;)&#125;// 创建一个运行 fn 的新 g，具有 narg 字节大小的参数，从 argp 开始。callerps 是 go 语句的起始地址。新创建的 g 会被放入 g 的队列中等待运行。func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) &#123; // 因为是在系统栈运行所以此时的 g 为 g0 _g_ := getg() ... // 获取 p _p_ := _g_.m.p.ptr() // 从 g 空闲列表中，根据 p 获得一个新的 g newg := gfget(_p_) // 初始化阶段，gfget 是不可能找到 g 的，也可能运行中本来就已经耗尽了 if newg == nil &#123; // 创建一个拥有 _StackMin (2kb) 大小的栈的 g newg = malg(_StackMin) // 将新创建的 g 从 _Gidle 更新为 _Gdead 状态 casgstatus(newg, _Gidle, _Gdead) // 将 Gdead 状态的 g 添加到 allg，这样 GC 不会扫描未初始化的栈 allgadd(newg) // publishes with a g-&gt;status of Gdead so GC scanner doesn't look at uninitialized stack. &#125; ... // 计算运行空间大小，与 spAlign 对齐 totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize // extra space in case of reads slightly beyond frame totalSize += -totalSize &amp; (sys.SpAlign - 1) // align to spAlign // 确定 sp 和参数入栈位置 sp := newg.stack.hi - totalSize spArg := sp ... // 处理参数，当有参数时，将参数拷贝到 goroutine 的执行栈中 if narg &gt; 0 &#123; // 从 argp 参数开始的位置，复制 narg 个字节到 spArg（参数拷贝） memmove(unsafe.Pointer(spArg), unsafe.Pointer(argp), uintptr(narg)) ... &#125; // 清理、创建并初始化的 g 的运行现场 memclrNoHeapPointers(unsafe.Pointer(&amp;newg.sched), unsafe.Sizeof(newg.sched)) // 设置 newg 的 sched 成员，调度器需要依靠这些字段才能把 goroutine 调度到 CPU 上运行。 newg.sched.sp = sp // newg 的栈顶 newg.stktopsp = sp // newg.sched.pc 表示当 newg 被调度起来运行时从这个地址开始执行指令，也说是 goexit 函数的第二条指令。 // 把 pc 设置成了 goexit 这个函数偏移 1 （ amd64 中 sys.PCQuantum 等于 1 ）的位置。 // 这里为什么 goexit 是第二条指令？ 需要看 gostartcallfn 函数。 newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function // +PCQuantum 从而前一个指令还在相同的函数内 newg.sched.g = guintptr(unsafe.Pointer(newg)) // gostartcallfn 会获取 fn 的函数地址，然后调用 gostartcall // gostartcall函数的主要作用有两个： // 调整 newg 的栈空间，把 goexit 函数的第二条指令的地址入栈，伪造成 goexit 函数调用了 fn ，从而使 fn 执行完成后执行 ret 指令时返回到 goexit 继续执行完成最后的清理工作； // 重新设置 newg.buf.pc 为需要执行的函数的地址，即 fn ，初始化时为 runtime.main 函数的地址。 gostartcallfn(&amp;newg.sched, fn) // 初始化 g 的基本状态 newg.gopc = callerpc //主要用于 traceback newg.ancestors = saveAncestors(callergp) // 调试相关，追踪调用方 // 设置 newg 的 startpc 为 fn.fn ，该成员主要用于函数调用栈的 traceback 和栈收缩 // newg 真正从哪里开始执行并不依赖于这个成员，而是 newg.sched.pc newg.startpc = fn.fn ... // 将 g 更换为 _Grunnable 状态 casgstatus(newg, _Gdead, _Grunnable) ... // 将这里新创建的 g 放入 p 的本地队列，如果已满，则放入全局队列，true 表示放入执行队列的下一个 (_p_.runnext)，false 表示放入队尾 runqput(_p_, newg, true) ...&#125;// src/runtime/stack.go// adjust Gobuf as if it executed a call to fn// and then did an immediate gosave.// 调整 Gobuf ，就好像它执行了对 fn 的调用了一样，然后立即进行 gosave 。func gostartcallfn(gobuf *gobuf, fv *funcval) &#123; var fn unsafe.Pointer if fv != nil &#123; fn = unsafe.Pointer(fv.fn) // fn: gorotine 的入口地址，初始化时对应的是 runtime.main ，其它对应各自的 gorotine 的入口地址。 &#125; else &#123; fn = unsafe.Pointer(funcPC(nilfunc)) &#125; gostartcall(gobuf, fn, unsafe.Pointer(fv))&#125;// src/runtime/sys_x86.go// adjust Gobuf as if it executed a call to fn with context ctxt// and then did an immediate gosave.、// 调整 Gobuf ，就好像它使用上下文 ctxt 执行了对 fn 的调用，然后立即执行了 gosave 一样。func gostartcall(buf *gobuf, fn, ctxt unsafe.Pointer) &#123; // newg 的栈顶，目前 newg 栈上只有 fn 函数的参数， sp 指向的是 fn 的第一参数 sp := buf.sp if sys.RegSize &gt; sys.PtrSize &#123; sp -= sys.PtrSize *(*uintptr)(unsafe.Pointer(sp)) = 0 &#125; sp -= sys.PtrSize // 栈空间是高地址向低地址增长，为返回地址预留空间 // 这里在伪装 fn 是被 goexit 函数调用的，使得 fn 执行完后返回到 goexit 继续执行，从而完成清理工作 *(*uintptr)(unsafe.Pointer(sp)) = buf.pc // 在栈上放入 goexit+1 的地址 buf.sp = sp // 新设置 newg 的栈顶寄存器 // 这里才真正让 newg 的 pc 寄存器指向 fn 函数，等到 newg 被调度起来运行时，调度器会把 buf.pc 放入 cpu 的 IP 寄存器， // 从而使 newg 得以在 cpu 上真正的运行起来。 buf.pc = uintptr(fn) buf.ctxt = ctxt&#125; &emsp;&emsp;上面我们可以看到， newproc 最终在 g0 上调用 newproc1 ，然后 newg := gfget(_p_) 获取一个 g ，如果获取不到则通过 malg （malg会设置其栈字段）新建一个 g （这个当然是新建），为其分配 2KB 大小的栈，设置其状态为 _Gdead 然后添加到全局变量 allgs 中。 &emsp;&emsp;接着会拷贝参数到 newg 的栈上，然后初始化 newg.sched ，其中最重要的莫过于 sp , pc 。注意 newg.sched.pc 先设置的是 goexit + 1 （也说是 goexit 函数的第二条指令。），然后调用了 gostartcallfn , gostartcallfn 会获取 fn 的函数地址，然后调用 gostartcall 。 &emsp;&emsp;gostartcall函数的主要作用有两个： 调整 newg 的栈空间，把 goexit 函数的第二条指令的地址入栈，伪造成 goexit 函数调用了 fn ，从而使 fn 执行完成后执行 ret 指令时返回到 goexit 继续执行完成最后的清理工作； 重新设置 newg.buf.pc 为需要执行的函数的地址，即 fn ，初始化时为 runtime.main 函数的地址。 &emsp;&emsp;然后设置 newg 的一些基本信息，设置为 _Grunnable 状态，然后设置为下一个待运行的。因为初始化的时候队列为空，不可能放到全局队列，p.runnext 也还没有，这里就设置到 p.runnext ，就等待调度了，用户确定不了什么时候开始执行。 开始调度循环&emsp;&emsp;前面创建了一个 goroutine，设置好了 sched 成员的 sp 和 pc 字段，并且将其添加到了 p0 的本地可运行队列，还没有绑定 m ，坐等调度器的调度。我们继续看 runtime·rt0_go 函数。 123456789101112131415// src/runtime/asm_amd64.sTEXT runtime·rt0_go(SB),NOSPLIT,$0 ... // start this M CALL runtime·mstart(SB) // 启动调度程序，调度到刚刚创建的 goroutine 执行，在 proc.go 函数原型： func mstart() CALL runtime·abort(SB) // mstart should never return // mstart 永远不会返回 RET ...// 声明全局的变量 mainPC 为 runtime.main 函数的地址，该变量为 read onlyDATA runtime·mainPC+0(SB)/8,$runtime·main(SB)GLOBL runtime·mainPC(SB),RODATA,$8 &emsp;&emsp;上面终于调用到 runtime·mstart 核心代码了，开启调度器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// src/runtime/proc.go// Called to start an M.//// This must not split the stack because we may not even have stack// bounds set up yet.//// May run during STW (because it doesn't have a P yet), so write// barriers are not allowed.// 启动 M ， M 的入口函数// 该函数不允许分段栈，因为我们甚至还没有设置栈的边界。它可能会在 STW 阶段运行（因为它还没有 P），所以 write barrier 也是不允许的////go:nosplit//go:nowritebarrierrecfunc mstart() &#123; _g_ := getg() // 确定执行栈的边界。通过检查 g 执行占的边界来确定是否为系统栈 osStack := _g_.stack.lo == 0 if osStack &#123; // Initialize stack bounds from system stack. // Cgo may have left stack size in stack.hi. // minit may update the stack bounds. // 根据系统栈初始化执行栈的边界。cgo 可能会离开 stack.hi 。minit 可能会更新栈的边界 size := _g_.stack.hi if size == 0 &#123; size = 8192 * sys.StackGuardMultiplier &#125; _g_.stack.hi = uintptr(noescape(unsafe.Pointer(&amp;size))) _g_.stack.lo = _g_.stack.hi - size + 1024 &#125; // Initialize stack guards so that we can start calling // both Go and C functions with stack growth prologues. // 初始化堆栈守卫，以便我们可以使用堆栈增长 prologue (序言) 开始调用Go和C函数。 _g_.stackguard0 = _g_.stack.lo + _StackGuard _g_.stackguard1 = _g_.stackguard0 // 启动 M mstart1() // Exit this thread. // 退出线程 if GOOS == "windows" || GOOS == "solaris" || GOOS == "plan9" || GOOS == "darwin" || GOOS == "aix" &#123; // Window, Solaris, Darwin, AIX and Plan 9 always system-allocate // the stack, but put it in _g_.stack before mstart, // so the logic above hasn't set osStack yet. // Window，Solaris，Darwin，AIX和Plan 9始终对栈进行系统分配，但将其放在mstart之前的_g_.stack中，因此上述逻辑尚未设置osStack。 osStack = true &#125; // 退出线程 mexit(osStack)&#125; &emsp;&emsp;mstart 主要获取当前的 g ，然后设置 stackguard0 ， stackguard1 ，然后直接调用 mstart1 了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// src/runtime/proc.gofunc mstart1() &#123; _g_ := getg() // 检查当前执行的 g 是不是 g0 if _g_ != _g_.m.g0 &#123; throw("bad runtime·mstart") &#125; // Record the caller for use as the top of stack in mcall and // for terminating the thread. // We're never coming back to mstart1 after we call schedule, // so other calls can reuse the current frame. // 这里会记录前一个调用者的状态， 包含 PC , SP 以及其他信息。这份记录会当作最初栈 (top stack)，给之后的 mcall 调用，也用来结束那个线程。 // 接下來在 mstart1 调用到 schedule 之后就再也不会回到这个地方了，所以其他调用可以重用当前帧。 // 借助编译器的帮助获取 PC 和 SP , 然后在 save 中更新当前 G 的 sched (type gobuf) 的一些成员， 保存调用者的 pc 和 sp ，让日后其他执行者执行 gogo 函数的时候使用。 save(getcallerpc(), getcallersp()) asminit() // 初始化汇编，但是 amd64 架构下不需要执行任何代码就立刻返回，其他像是 arm、386 才有一些需在这里设定一些 CPU 相关的內容。 minit() // 初始化m 包括信号栈和信号掩码，procid // Install signal handlers; after minit so that minit can // prepare the thread to be able to handle the signals. // 设置信号 handler ；在 minit 之后，因为 minit 可以准备处理信号的的线程 if _g_.m == &amp;m0 &#123; // 在当前的 goroutine 的所属执行者是 m0 的情況下进入 mstartm0 函数，正式启动在此之前的 signal 处理设定，其中最关键的是 initsig 函数。 mstartm0() &#125; // 执行启动函数 if fn := _g_.m.mstartfn; fn != nil &#123; fn() &#125; // 如果当前 m 并非 m0，则要求绑定 p if _g_.m != &amp;m0 &#123; acquirep(_g_.m.nextp.ptr()) _g_.m.nextp = 0 &#125; // 彻底准备好，开始调度，永不返回 schedule()&#125;// mstartm0 implements part of mstart1 that only runs on the m0.//// Write barriers are allowed here because we know the GC can't be// running yet, so they'll be no-ops.//// mstartm0 实现了一部分 mstart1，只运行在 m0 上。允许 write barrier，因为我们知道 GC 此时还不能运行，因此他们没有操作。//go:yeswritebarrierrecfunc mstartm0() &#123; // Create an extra M for callbacks on threads not created by Go. // An extra M is also needed on Windows for callbacks created by // syscall.NewCallback. See issue #6751 for details. // 创建一个额外的 M 处理 non-Go 线程（cgo 调用中产生的线程）的回调，并且只创建一个。windows 上也需要额外 M 来处理 syscall.NewCallback 产生的回调，见 issue #6751 if (iscgo || GOOS == "windows") &amp;&amp; !cgoHasExtraM &#123; cgoHasExtraM = true newextram() &#125; // 初始化信号。 initsig(false)&#125;// save updates getg().sched to refer to pc and sp so that a following// gogo will restore pc and sp.//// save must not have write barriers because invoking a write barrier// can clobber getg().sched.// save 更新了 getg().sched 的 pc 和 sp 的指向，并允许 gogo 能够恢复到 pc 和 sp 。 save 不允许 write barrier， 因为会破坏 getg().sched 。////go:nosplit//go:nowritebarrierrecfunc save(pc, sp uintptr) &#123; _g_ := getg() _g_.sched.pc = pc _g_.sched.sp = sp _g_.sched.lr = 0 _g_.sched.ret = 0 _g_.sched.g = guintptr(unsafe.Pointer(_g_)) // We need to ensure ctxt is zero, but can't have a write // barrier here. However, it should always already be zero. // Assert that. // 我们必须确保 ctxt 为零，但这里不允许 write barrier。 所以这里只是做一个断言。 if _g_.sched.ctxt != nil &#123; badctxt() &#125;&#125; &emsp;&emsp;首先调用 save 函数来保存 g0 的调度信息。save 函数执行完成后，继续其它跟 m 相关的一些初始化，然后调用调度系统的核心函数 schedule() 完成 goroutine 的调度，每次调度 goroutine 都是从 schedule 函数开始的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418// src/runtime/proc.go// One round of scheduler: find a runnable goroutine and execute it.// Never returns.// 调度器的一轮：找到 runnable goroutine 并进行执行且永不返回。func schedule() &#123; _g_ := getg() // 调度的时候， m 不能持有 locks if _g_.m.locks != 0 &#123; throw("schedule: holding locks") &#125; // 如果当前 M 锁定了某个 G ，那么应该交出P，进入休眠。等待某个 M 调度拿到 lockedg ，然后唤醒 lockedg 的 M if _g_.m.lockedg != 0 &#123; stoplockedm() // 停止当前正在执行锁住的 g 的 m 的执行，直到 g 重新变为 runnable ， 被唤醒 。 返回时关联了 P execute(_g_.m.lockedg.ptr(), false) // Never returns. &#125; // We should not schedule away from a g that is executing a cgo call, // since the cgo call is using the m's g0 stack. // 我们不应该调度一个正在执行 cgo 调用的 g ， 因为 cgo 在使用当前 m 的 g0 栈 if _g_.m.incgo &#123; throw("schedule: in cgo") &#125;top: // 如果当前 GC 需要（STW), 则调用 gcstopm 休眠当前的 M if sched.gcwaiting != 0 &#123; gcstopm() goto top &#125; // 如果有安全点函数， 则执行 if _g_.m.p.ptr().runSafePointFn != 0 &#123; runSafePointFn() &#125; var gp *g var inheritTime bool // 如果启动 trace 或等待 trace reader if trace.enabled || trace.shutdown &#123; // 有 trace reader 需要被唤醒则标记 _Grunnable gp = traceReader() if gp != nil &#123; casgstatus(gp, _Gwaiting, _Grunnable) traceGoUnpark(gp, 0) &#125; &#125; // 如果当前 GC 正在标记阶段，允许置黑对象，则查找有没有待运行的 GC Worker, GC Worker 也是一个 G if gp == nil &amp;&amp; gcBlackenEnabled != 0 &#123; gp = gcController.findRunnableGCWorker(_g_.m.p.ptr()) &#125; // 说明不在 gc if gp == nil &#123; // Check the global runnable queue once in a while to ensure fairness. // Otherwise two goroutines can completely occupy the local runqueue // by constantly respawning each other. // 每调度 61 次，就检查一次全局队列，保证公平性。否则两个 goroutine 可以通过不断地互相 respawn（重生） 一直占领本地的 runqueue if _g_.m.p.ptr().schedtick%61 == 0 &amp;&amp; sched.runqsize &gt; 0 &#123; lock(&amp;sched.lock) gp = globrunqget(_g_.m.p.ptr(), 1) unlock(&amp;sched.lock) &#125; &#125; if gp == nil &#123; // 从p的本地队列中获取 gp, inheritTime = runqget(_g_.m.p.ptr()) // 本地有 g ，则 m 不应该在 spinning 状态 if gp != nil &amp;&amp; _g_.m.spinning &#123; throw("schedule: spinning with local work") &#125; &#125; if gp == nil &#123; // 想尽办法找到可运行的 G ，找不到就不用返回了 gp, inheritTime = findrunnable() // blocks until work is available &#125; // 这个时候肯定取到 g 了 // This thread is going to run a goroutine and is not spinning anymore, // so if it was marked as spinning we need to reset it now and potentially // start a new spinning M. // 该线程将运行 goroutine ，并且不再 spinning ，因此，如果将其标记为 spinning ，则需要立即将其重置并可能启动新的 spinning M 。 if _g_.m.spinning &#123; // 如果 m 是 spinning 状态，则： // 1. 从 spinning -&gt; non-spinning // 2. 在没有 spinning 的 m 的情况下，再多创建一个新的 spinning m resetspinning() &#125; // 如果禁用用户地 G 调度，并且 gp 不能够调度， 表示 gp 是用户 G ，不是系统 G if sched.disable.user &amp;&amp; !schedEnabled(gp) &#123; // Scheduling of this goroutine is disabled. Put it on // the list of pending runnable goroutines for when we // re-enable user scheduling and look again. // 禁用此 goroutine 的调度。 当我们重新启用用户调度并再次查看时，将其放在待处理的可运行 goroutine 列表中。 lock(&amp;sched.lock) // 锁住后重新检测 if schedEnabled(gp) &#123; // Something re-enabled scheduling while we // were acquiring the lock. // 当我们之前正在获取锁的时候，可能有什么重新启动了调度， 也就是锁住之前，可能哪里重新启动了用户 g 调度。 unlock(&amp;sched.lock) &#125; else &#123; // 加入到禁用掉的等待的可运行的 G 队尾 sched.disable.runnable.pushBack(gp) sched.disable.n++ unlock(&amp;sched.lock) goto top &#125; &#125; // 如果 gp 锁定了 m if gp.lockedm != 0 &#123; // Hands off own p to the locked m, // then blocks waiting for a new p. // 让出 gp 给其锁定的 m ，然后阻塞等待新的 p startlockedm(gp) // 调度锁定的 m 来运行锁定的 gp goto top &#125; // 开始执行 execute(gp, inheritTime)&#125;// Finds a runnable goroutine to execute.// Tries to steal from other P's, get g from global queue, poll network.// 寻找一个可运行的 goroutine 来执行。尝试从其他的 P 偷取、从本地或者全局队列中获取、pollnet 。func findrunnable() (gp *g, inheritTime bool) &#123; _g_ := getg() // The conditions here and in handoffp must agree: if // findrunnable would return a G to run, handoffp must start // an M. // 这里的条件与 handoffp 中的条件必须一致：如果 findrunnable 将返回 G 来运行，handoffp 必须启动 M 。top: _p_ := _g_.m.p.ptr() if sched.gcwaiting != 0 &#123; gcstopm() // 如果在 gc，则 park 当前 m，直到被 unpark 后回到 top goto top &#125; if _p_.runSafePointFn != 0 &#123; runSafePointFn() // 如果需要执行安全点函数，则执行 &#125; if fingwait &amp;&amp; fingwake &#123; if gp := wakefing(); gp != nil &#123; ready(gp, 0, true) &#125; &#125; // cgo 调用被终止，继续进入 if *cgo_yield != nil &#123; asmcgocall(*cgo_yield, nil) &#125; // local runq // 取本地队列 local runq，如果已经拿到，立刻返回 if gp, inheritTime := runqget(_p_); gp != nil &#123; return gp, inheritTime &#125; // global runq // 全局队列 global runq，如果已经拿到，立刻返回 if sched.runqsize != 0 &#123; lock(&amp;sched.lock) gp := globrunqget(_p_, 0) unlock(&amp;sched.lock) if gp != nil &#123; return gp, false &#125; &#125; // Poll network. // This netpoll is only an optimization before we resort to stealing. // We can safely skip it if there are no waiters or a thread is blocked // in netpoll already. If there is any kind of logical race with that // blocked thread (e.g. it has already returned from netpoll, but does // not set lastpoll yet), this thread will do blocking netpoll below // anyway. // Poll 网络，优先级比从其他 P 中偷要高。在我们尝试去其他 P 偷之前，这个 netpoll 只是一个优化。如果没有 waiter 或 netpoll 中的线程已被阻塞， // 则可以安全地跳过它。如果有任何类型的逻辑竞争与被阻塞的线程（例如它已经从 netpoll 返回，但尚未设置 lastpoll），该线程无论如何都将阻塞 netpoll 。 // netpoll 已经初始化了，并且没有在等待 netpoll 的 g ，并且 sched.lastpoll != 0 ， 下面候可能将 sched.lastpoll 设置为 0 ，然后阻塞调用 // netpoll(true)，返回后才设置 lastpoll ， 如果 sched.lastpoll == 0 的话，则表示 netpoll 还在阻塞， 这时候是 netpool 没有就绪 g 的。 if netpollinited() &amp;&amp; atomic.Load(&amp;netpollWaiters) &gt; 0 &amp;&amp; atomic.Load64(&amp;sched.lastpoll) != 0 &#123; // 轮询就绪的网络链接，查找 runnable G if list := netpoll(false); !list.empty() &#123; // non-blocking gp := list.pop() // 获取一个 injectglist(&amp;list) // 将 netpool 中剩余的 runnable g 列表插入到调度器中 casgstatus(gp, _Gwaiting, _Grunnable) // 设置状态为 _Grunnable if trace.enabled &#123; traceGoUnpark(gp, 0) &#125; // 返回从 netpoll 中窃取到的 g return gp, false &#125; &#125; // Steal work from other P's. // 从其他 P 中窃取 work procs := uint32(gomaxprocs) if atomic.Load(&amp;sched.npidle) == procs-1 &#123; // Either GOMAXPROCS=1 or everybody, except for us, is idle already. // New work can appear from returning syscall/cgocall, network or timers. // Neither of that submits to local run queues, so no point in stealing. // GOMAXPROCS=1 或除我们之外的每个 P 都空闲。 通过返回 syscall/cgocall，network 或 timers，可以找到新 P。 // 两者都不会提交到本地运行队列，因此在窃取方面毫无意义。 goto stop &#125; // If number of spinning M's &gt;= number of busy P's, block. // This is necessary to prevent excessive CPU consumption // when GOMAXPROCS&gt;&gt;1 but the program parallelism is low. // 如果 spinning 状态下 m 的数量 &gt;= busy 状态下 p 的数量，直接进入阻塞。该步骤是有必要的，它用于当 GOMAXPROCS&gt;&gt;1 时 // 但程序的并行机制很慢时昂贵的 CPU 消耗。 if !_g_.m.spinning &amp;&amp; 2*atomic.Load(&amp;sched.nmspinning) &gt;= procs-atomic.Load(&amp;sched.npidle) &#123; goto stop &#125; // 如果 m 是 non-spinning 状态，切换为 spinning if !_g_.m.spinning &#123; _g_.m.spinning = true atomic.Xadd(&amp;sched.nmspinning, 1) &#125; for i := 0; i &lt; 4; i++ &#123; // 随机窃取 for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() &#123; if sched.gcwaiting != 0 &#123; goto top // 已经进入了 GC? 回到 top ，park 当前的 m &#125; // 如果偷了3次都偷不到，连 p.runnext (是当前G准备好的可运行G) 都窃取 stealRunNextG := i &gt; 2 // first look for ready queues with more than 1 g if gp := runqsteal(_p_, allp[enum.position()], stealRunNextG); gp != nil &#123; // 窃取到了就返回 return gp, false &#125; &#125; &#125;stop: // We have nothing to do. If we're in the GC mark phase, can // safely scan and blacken objects, and have work to do, run // idle-time marking rather than give up the P. // 没有任何 work 可做。如果我们在 GC mark 阶段，则可以安全的扫描并 blacken 对象，然后便有 work 可做，运行 idle-time 标记而非直接放弃当前的 P。 if gcBlackenEnabled != 0 &amp;&amp; _p_.gcBgMarkWorker != 0 &amp;&amp; gcMarkWorkAvailable(_p_) &#123; _p_.gcMarkWorkerMode = gcMarkWorkerIdleMode gp := _p_.gcBgMarkWorker.ptr() casgstatus(gp, _Gwaiting, _Grunnable) if trace.enabled &#123; traceGoUnpark(gp, 0) &#125; return gp, false &#125; // wasm only: // If a callback returned and no other goroutine is awake, // then pause execution until a callback was triggered. // 仅限于 wasm 。如果一个回调返回后没有其他 goroutine 是苏醒的。则暂停执行直到回调被触发。 if beforeIdle() &#123; // At least one goroutine got woken. // 至少一个 goroutine 被唤醒 goto top &#125; // Before we drop our P, make a snapshot of the allp slice, // which can change underfoot once we no longer block // safe-points. We don't need to snapshot the contents because // everything up to cap(allp) is immutable. // 放弃当前的 P 之前，对 allp 做一个快照。一旦我们不再阻塞在 safe-point 时候，可以立刻在下面进行修改。 // 我们不需要对内容进行快照，因为 cap(allp) 的所有内容都是不可变的。 allpSnapshot := allp // return P and block // 准备归还 p，对调度器加锁 lock(&amp;sched.lock) // GC 或 运行安全点函数，则回到 top if sched.gcwaiting != 0 || _p_.runSafePointFn != 0 &#123; unlock(&amp;sched.lock) goto top &#125; // 全局队列中又发现了 g if sched.runqsize != 0 &#123; gp := globrunqget(_p_, 0) unlock(&amp;sched.lock) return gp, false &#125; // 取消关联 p 和当前 m if releasep() != _p_ &#123; throw("findrunnable: wrong p") &#125; // 将 p 放入 idle 链表 pidleput(_p_) // 完成归还，解锁 unlock(&amp;sched.lock) // Delicate dance: thread transitions from spinning to non-spinning state, // potentially concurrently with submission of new goroutines. We must // drop nmspinning first and then check all per-P queues again (with // #StoreLoad memory barrier in between). If we do it the other way around, // another thread can submit a goroutine after we've checked all run queues // but before we drop nmspinning; as the result nobody will unpark a thread // to run the goroutine. // If we discover new work below, we need to restore m.spinning as a signal // for resetspinning to unpark a new worker thread (because there can be more // than one starving goroutine). However, if after discovering new work // we also observe no idle Ps, it is OK to just park the current thread: // the system is fully loaded so no spinning threads are required. // Also see "Worker thread parking/unparking" comment at the top of the file. // 这里要非常小心: 线程从 spinning 到 non-spinning 状态的转换，可能与新 goroutine 的提交同时发生。 我们必须首先降低 nmspinning， // 然后再次检查所有的 per-P 队列（并在期间伴随 #StoreLoad 内存屏障）。如果反过来，其他线程可以在我们检查了所有的队列、然后提交一个 // goroutine、再降低 nmspinning ，进而导致无法 unpark 一个线程来运行那个 goroutine 了。 // 如果我们发现下面的新 work，我们需要恢复 m.spinning 作为重置的信号，以取消 park 新的工作线程（因为可能有多个饥饿的 goroutine）。 // 但是，如果在发现新 work 后我们也观察到没有空闲 P，可以暂停当前线程。因为系统已满载，因此不需要 spinning 线程。 // 请参考此文件顶部 "工作线程 parking/unparking" 的注释。 wasSpinning := _g_.m.spinning // 记录下之前的状态是否为 spinning if _g_.m.spinning &#123; // spinning 到 non-spinning 状态的转换，并递减 sched.nmspinning _g_.m.spinning = false if int32(atomic.Xadd(&amp;sched.nmspinning, -1)) &lt; 0 &#123; throw("findrunnable: negative nmspinning") &#125; &#125; // check all runqueues once again // 再次检查所有的 runqueue for _, _p_ := range allpSnapshot &#123; // 如果这时本地队列不空 if !runqempty(_p_) &#123; // 锁住调度，重新获取空闲的 p lock(&amp;sched.lock) _p_ = pidleget() unlock(&amp;sched.lock) // 如果能获取到空闲的 p if _p_ != nil &#123; // p 与当前 m 关联 acquirep(_p_) // 如果此前已经被切换为 spinning if wasSpinning &#123; // 重新切换回 non-spinning _g_.m.spinning = true atomic.Xadd(&amp;sched.nmspinning, 1) &#125; // 这时候是有 work 的，回到顶部重新找 g goto top &#125; // 没有空闲的 p，不需要重新找 g 了 break &#125; &#125; // Check for idle-priority GC work again. // 再次检查 idle-priority GC work 。和上面重新找 runqueue 的逻辑类似 // gcMarkWorkAvailable 参数为 nil ，在这种情况下，它仅检查全局工作任务。 if gcBlackenEnabled != 0 &amp;&amp; gcMarkWorkAvailable(nil) &#123; lock(&amp;sched.lock) // 获取空闲的 p _p_ = pidleget() if _p_ != nil &amp;&amp; _p_.gcBgMarkWorker == 0 &#123; // 获取到的 p 没有 background mask worker， 重新放回空闲 p 列表 pidleput(_p_) _p_ = nil &#125; unlock(&amp;sched.lock) // 如果能获取到空闲的 p if _p_ != nil &#123; // p 与当前 m 关联 acquirep(_p_) // 如果此前已经被切换为 spinning if wasSpinning &#123; // 重新切换回 non-spinning _g_.m.spinning = true atomic.Xadd(&amp;sched.nmspinning, 1) &#125; // Go back to idle GC check. // 这时候是有 work 的，回到顶部重新找 g goto stop &#125; &#125; // poll network // poll 网络。和上面重新找 runqueue 的逻辑类似 // netpoll 已经初始化了，并且没有在等待 netpoll 的 g ，并且 sched.lastpoll != 0 ，满足的话，会设置 sched.lastpoll = 0 // atomic.Xchg64(&amp;sched.lastpoll, 0) 设置 sched.lastpoll = 0 ， 并返回原来的 sched.lastpoll if netpollinited() &amp;&amp; atomic.Load(&amp;netpollWaiters) &gt; 0 &amp;&amp; atomic.Xchg64(&amp;sched.lastpoll, 0) != 0 &#123; if _g_.m.p != 0 &#123; throw("findrunnable: netpoll with p") &#125; if _g_.m.spinning &#123; throw("findrunnable: netpoll with spinning") &#125; list := netpoll(true) // block until new work is available // 阻塞直到有新的 work atomic.Store64(&amp;sched.lastpoll, uint64(nanotime())) // 存储上一次 netpool 时间 // netpoll 的 g list 不会空 if !list.empty() &#123; lock(&amp;sched.lock) // 获取空闲的 p _p_ = pidleget() unlock(&amp;sched.lock) // 如果能获取到空闲的 p if _p_ != nil &#123; // p 与当前 m 关联 acquirep(_p_) gp := list.pop() // 获取一个 injectglist(&amp;list) // 将 netpool 中剩余的 runnable g 列表插入到调度器中 casgstatus(gp, _Gwaiting, _Grunnable) // 设置状态为 _Grunnable if trace.enabled &#123; traceGoUnpark(gp, 0) &#125; // 返回从 netpoll 中窃取到的 g return gp, false &#125; // 如果没有获取到 p ，将 netpool 中获取到的 runnable g 列表插入到调度器中 injectglist(&amp;list) &#125; &#125; // 确实找不到，park 当前的 m stopm() // m unpark 后继续找 goto top&#125; &emsp;&emsp;schedule 大致的执行流程是： 如果当前 M 锁定了某个 G ，那么应该交出P，进入休眠。等待某个 M 调度拿到 lockedg ，然后唤醒 lockedg 的 M 如果当前 GC 需要（STW), 则调用 gcstopm 休眠当前的 M 如果有安全点函数， 则执行 找一个 g 来执行，找 g 的过程大致如下： 如果当前 GC 正在标记阶段，允许置黑对象，则查找有没有待运行的 GC Worker, GC Worker 也是一个 G 调度器每调度 61 次的时候，都会尝试从全局队列里取出待运行的 goroutine 来运行，调用 globrunqget 调用 runqget 从 P 本地可运行队列先选出一个可运行的 goroutine 。 调用 findrunnable 尝试从其他的 P 偷取、从本地或者全局队列中获取、pollnet ，如果没找到会 pack 。如果没找到则调用 stopm 来 park m ，等到有任务的时候唤醒。 调用 execute(gp, inheritTime) 开始执行 g 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// src/runtime/proc.go// Schedules gp to run on the current M.// If inheritTime is true, gp inherits the remaining time in the// current time slice. Otherwise, it starts a new time slice.// Never returns.//// Write barriers are allowed because this is called immediately after// acquiring a P in several places.//// 在当前 M 上调度 gp。 如果 inheritTime 为 true，则 gp 继承剩余的时间片。否则从一个新的时间片开始。 此函数永不返回。// 该函数允许 write barrier 因为它是在 acquire P 之后的调用的。////go:yeswritebarrierrecfunc execute(gp *g, inheritTime bool) &#123; _g_ := getg() // 将 g 正式切换为 _Grunning 状态 casgstatus(gp, _Grunnable, _Grunning) gp.waitsince = 0 // 清除等待时间，现在开始执行了 gp.preempt = false // 关闭抢占 gp.stackguard0 = gp.stack.lo + _StackGuard // 设置栈边界检测 if !inheritTime &#123; // 如果不继承时间片，则开始新的 _g_.m.p.ptr().schedtick++ &#125; _g_.m.curg = gp // 设置当前循运行的 g gp.m = _g_.m // 设置运行的g的 m // Check whether the profiler needs to be turned on or off. // 检查是否需要打开或关闭 cpu profiler 。 hz := sched.profilehz if _g_.m.profilehz != hz &#123; setThreadCPUProfiler(hz) &#125; // trace if trace.enabled &#123; // GoSysExit has to happen when we have a P, but before GoStart. // So we emit it here. if gp.syscallsp != 0 &amp;&amp; gp.sysblocktraced &#123; traceGoSysExit(gp.sysexitticks) &#125; traceGoStart() &#125; // 从gobuf恢复状态，开始执行，gogo 实现在 asm_amd64.s 中 gogo(&amp;gp.sched)&#125; &emsp;&emsp;execute 这里首先将 p 的状态改为 _Grunning ，然年绑定 m 和 p ，让后调用 gogo(&amp;gp.sched) 来执行 g 。 gogo 是由汇编实现的。 1234567891011121314151617181920// src/runtime/asm_amd64.s// func gogo(buf *gobuf)// restore state from Gobuf; longjmp// 从 Gobuf 恢复状态; longjmpTEXT runtime·gogo(SB), NOSPLIT, $16-8 MOVQ buf+0(FP), BX // gobuf // BX = buf 运行现场 MOVQ gobuf_g(BX), DX // DX = buf.g MOVQ 0(DX), CX // make sure g != nil // 确保 g != nil get_tls(CX) // CX = 当前 p MOVQ DX, g(CX) // 当前 g.g = buf.g MOVQ gobuf_sp(BX), SP // restore SP // SP = buf.sp MOVQ gobuf_ret(BX), AX // AX = buf.ret MOVQ gobuf_ctxt(BX), DX // DX = buf.ctxt MOVQ gobuf_bp(BX), BP // BP = buf.bp MOVQ $0, gobuf_sp(BX) // clear to help garbage collector // buf.sp = 0 清理数据有助于 GC MOVQ $0, gobuf_ret(BX) // buf.ret = 0 MOVQ $0, gobuf_ctxt(BX) // buf.ctxt = 0 MOVQ $0, gobuf_bp(BX) // buf.bp = 0 MOVQ gobuf_pc(BX), BX // BX = buf.pc 获取 g 要执行的函数的入口地址 JMP BX // 跳转到对应的 buf.pc ，开始执行 &emsp;&emsp;gogo 中重点在 MOVQ gobuf_pc(BX), BX ， 这个 pc 值是 gp 将要执行的指令，在初始化中，也就是 runtime.main 的第一条指令，然后 JMP BX 开始执行。 &emsp;&emsp;OK 到这里， runtime·main 终于动起来了，我们来看看 runtime.main 吧 ， 看看啥时候能运行行用户代码 package main 中的 main 函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// src/runtime/proc.go// The main goroutine.// 主 goroutine，也就是runtime·mainPCfunc main() &#123; // 获取当前的G, G为TLS(Thread Local Storage) g := getg() ··· // Max stack size is 1 GB on 64-bit, 250 MB on 32-bit. // Using decimal instead of binary GB and MB because // they look nicer in the stack overflow failure message. // 执行栈的最大限制： 1GB on 64-bit， 250 MB on 32-bit。使用十进制而不是二进制GB和MB，因为它们在堆栈溢出失败消息中好看些。 if sys.PtrSize == 8 &#123; maxstacksize = 1000000000 &#125; else &#123; maxstacksize = 250000000 &#125; // Allow newproc to start new Ms. // 表示main goroutine启动了，接下来允许 newproc 启动新的 m mainStarted = true ··· // 执行 runtime.main 函数的 G 必须是绑定在 m0 上的 if g.m != &amp;m0 &#123; throw("runtime.main not on m0") &#125; // 执行初始化运行时 runtime_init() // must be before defer // defer 必须在此调用结束后才能使用 if nanotime() == 0 &#123; throw("nanotime returning zero") &#125; ··· main_init_done = make(chan bool) ··· // 执行 main_init，进行间接调用，因为链接器在设定运行时的时候不知道 main 包的地址 fn := main_init // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime fn() close(main_init_done) needUnlock = false unlockOSThread() ··· // 执行用户 main 包中的 main 函数，处理为非间接调用，因为链接器在设定运行时不知道 main 包的地址 fn = main_main // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime fn() ··· // 退出执行，返回退出状态码 exit(0) ···&#125; &emsp;&emsp;runtime·main 限制了最大栈（近似 1GB on 64-bit， 250 MB on 32-bit），结合前面的，我们就知道了， go 动态栈的范围是 2KB 到 1GB/250MB 。然后 fn = main_main ; fn() 终于执行到用户代码了，真不容易啊！然后直接调用 exit 结束进程了。注意这里是 main goroutine ! &emsp;&emsp;咦，咋就这么结束了？还有其它的 goroutine 呢？ 都不管了？ &emsp;&emsp;我们回忆以下，main goroutine 的入口函数是 runtime·mainPC 也就是 runtime.main 函数，通过 schedule() -&gt; execute() -&gt; gogo() 中 gogo 函数用汇编跳转的，后面没有指令了，返回到哪里？。另外 runtime.main 会等用户代码执行完返回，我们用户代码返回了，这里 exit 也合情合理。 &emsp;&emsp;之前有分析过， newproc1 的 newg.sched.pc = funcPC(goexit) + sys.PCQuantum 的时候有伪造 goexit 函数调用 goroutine 的入口函数，上面说分析了 main goroutine 直接退出了， 非 main goroutine 执行完成后就会返回到 goexit 继续执行， 我们来看看非 main goroutine的后续处理 goexit 。 123456789101112131415161718192021222324// src/runtime/asm_amd64.s// The top-most function running on a goroutine// returns to goexit+PCQuantum.// 在 goroutine 上运行的最顶层函数将返回goexit + PCQuantum。// goroutine 执行完成后返回后执行： CALL runtime·goexit1(SB)TEXT runtime·goexit(SB),NOSPLIT,$0-0 BYTE $0x90 // NOP CALL runtime·goexit1(SB) // does not return // 永不返回 // traceback from goexit1 must hit code range of goexit BYTE $0x90 // NOP// src/runtime/proc.go// Finishes execution of the current goroutine.// 完成当前 goroutine 的执行func goexit1() &#123; if raceenabled &#123; racegoend() &#125; if trace.enabled &#123; traceGoEnd() &#125; // 开始收尾工作 mcall(goexit0)&#125; &emsp;&emsp;之前分析过， gostartcallfn 是把 goexit 函数的第二条指令的地址入栈，伪造成 goexit 函数调用了 fn ，也就是这里的 runtime·goexit1 函数，goexit1 调用到 mcall(goexit0) 了， mcall 切换到 g0 然后执行 goexit0 ，这里再继续可能看 goexit0 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// goexit continuation on g0.// goexit 继续在 g0 上执行func goexit0(gp *g) &#123; _g_ := getg() // 切换当前的 g 为 _Gdead casgstatus(gp, _Grunning, _Gdead) // 如果是系统 g ， 更新统计信息 if isSystemGoroutine(gp, false) &#123; atomic.Xadd(&amp;sched.ngsys, -1) &#125; // 清理 gp.m = nil locked := gp.lockedm != 0 gp.lockedm = 0 _g_.m.lockedg = 0 gp.paniconfault = false gp._defer = nil // should be true already but just in case. // 应该已经为 true，但以防万一 gp._panic = nil // non-nil for Goexit during panic. points at stack-allocated data. // Goexit 中 panic 则不为 nil， 指向栈分配的数据 gp.writebuf = nil gp.waitreason = 0 gp.param = nil gp.labels = nil gp.timer = nil if gcBlackenEnabled != 0 &amp;&amp; gp.gcAssistBytes &gt; 0 &#123; // Flush assist credit to the global pool. This gives // better information to pacing if the application is // rapidly creating an exiting goroutines. // 刷新 assist credit 到全局池。如果政协在快速创建已存在的 goroutine，这可以为 pacing 提供更好的信息。 scanCredit := int64(gcController.assistWorkPerByte * float64(gp.gcAssistBytes)) atomic.Xaddint64(&amp;gcController.bgScanCredit, scanCredit) gp.gcAssistBytes = 0 &#125; // Note that gp's stack scan is now "valid" because it has no // stack. // 请注意， gp 的栈扫描现在 “有效” ，因为它没有栈。 gp.gcscanvalid = true // 移除 m 与当前 goroutine m-&gt;curg 之间的关联 dropg() if GOARCH == "wasm" &#123; // no threads yet on wasm // wasm 目前还没有线程支持 gfput(_g_.m.p.ptr(), gp) // 将 g 放进 gfree 链表中等待复用 schedule() // never returns &#125; // lockOSThread/unlockOSThread 调用不匹配 if _g_.m.lockedInt != 0 &#123; print("invalid m-&gt;lockedInt = ", _g_.m.lockedInt, "\n") throw("internal lockOSThread error") &#125; gfput(_g_.m.p.ptr(), gp) // 将 g 放进 gfree 链表中等待复用 if locked &#123; // The goroutine may have locked this thread because // it put it in an unusual kernel state. Kill it // rather than returning it to the thread pool. // 该 goroutine 可能在当前线程上锁住，因为它可能导致了不正常的内核状态。这时候 kill 该线程，而非将 m 放回到线程池。 // Return to mstart, which will release the P and exit // the thread. // 此举会返回到 mstart，从而释放当前的 P 并退出该线程 if GOOS != "plan9" &#123; // See golang.org/issue/22227. // mstart1 调用 save 保存的，这里恢复，则结束线程 gogo(&amp;_g_.m.g0.sched) &#125; else &#123; // Clear lockedExt on plan9 since we may end up re-using // this thread. // 因为我们可能已重用此线程结束，在 plan9 上清除 lockedExt _g_.m.lockedExt = 0 &#125; &#125; // 再次进行调度 schedule()&#125; &emsp;&emsp;从上面我们可以看出，goexit0 主要是做一些清理工作，然后调用 schedule 继续调度。主要如下： 将g 的状态从 _Grunning 变更为 _Gdead 清零 g 的一些字段 调用 dropg 移除 m 与当前 goroutine m-&gt;curg 之间的关联 调用 gfput(g.m.p.ptr(), gp) 将 g 放进 gfree 链表中等待复用 调用 schedule 再次进行调度。 &emsp;&emsp;至此，GO schedule 基本分析完了， Go Start The World ! &emsp;&emsp;那么我们这里总结一下： &emsp;&emsp;如图所示，rt0_go 负责 Go 程序启动的所有初始化，中间进行了很多初始化工作，调用 mstart 之前，已经切换到了 g0 栈，图中不同色块表示使用不同的栈空间。 &emsp;&emsp;接着调用 gogo 函数，完成从 g0 栈到用户 goroutine 栈的切换，包括 main goroutine 和普通 goroutine。 &emsp;&emsp;之后，执行 main 函数或者用户自定义的 goroutine 任务。 &emsp;&emsp;执行完成后，main goroutine 直接调用 eixt(0) 退出，普通 goroutine 则调用 goexit -&gt; goexit1 -&gt; mcall，完成普通 goroutine 退出后的清理工作，然后切换到 g0 栈，调用 goexit0 函数，将普通 goroutine 添加到缓存池中，再调用 schedule 函数进行新一轮的调度。 12schedule() -&gt; execute() -&gt; gogo() -&gt; goroutine 任务 -&gt; goexit() -&gt; goexit1() -&gt; mcall() -&gt; goexit0() -&gt; schedule() GPM 状态转变M P G]]></content>
  </entry>
  <entry>
    <title><![CDATA[【golang源码分析】之GPM概述]]></title>
    <url>%2F2020%2F01%2F29%2F%E3%80%90golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%E4%B9%8BGPM%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;我们知道 golang 原生支持并发，goroutine 就是其设计的核心。 goroutine 是用户态线程，也就是协程。这是对内核透明的，也就是系统并不知道有协程的存在，是完全由用户自己的程序进行调度的，当然这不需要我们做什么工作，golang 已经帮我们处理了。在如今处处高并发的时代，很多库包括语言都有协程的影子。例如，腾讯的 libco 是微信后台大规模使用的c/c++协程库；lua 也是有协程的。 进程线程协程&emsp;&emsp;为什么要多此一举来设计协程呢？还要自己来负责调度。 进程：分配完整独立的地址空间，拥有自己独立的堆和栈，既不共享堆，亦不共享栈，进程的切换只发生在内核态，由操作系统调度。 线程：和其它本进程的线程共享地址空间，拥有自己独立的栈和共享的堆，共享堆，不共享栈，线程的切换一般也由操作系统调度(标准线程是的)。 协程：和线程类似，共享堆，不共享栈，协程的切换一般由程序员在代码中显式控制。 &emsp;&emsp;进程切换分两步： 切换页目录以使用新的地址空间 切换内核栈和硬件上下文 &emsp;&emsp;对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。 &emsp;&emsp;切换的性能消耗： 线程上下文切换和进程上下文切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。 另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor’s Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。 &emsp;&emsp;进程和线程的切换主要依赖于时间片的控制，而协程的切换则主要依赖于自身，这样的好处是避免了无意义的调度，由此可以提高性能，但也因此，程序员必须自己承担调度的责任。另外，协程一般拥有更小的创建，销毁和切换代价，以及更合理的内存分配，这也进一步提高性能。 Goroutine 与线程&emsp;&emsp;我们这里从内存占用，创建销毁和切换代价来对比下 Goroutine 与线程，来了解轻量的 Goroutine 。 内存占用&emsp;&emsp;创建一个 goroutine 的栈内存消耗为 2KB(_StackMin = 2048)，实际运行过程中，如果栈空间不够用，会自动进行扩容，最大 1GB(maxstacksize = 1 &lt;&lt; 20) 。创建一个 thread 则默认需要消耗 8 MB (64bit系统) 栈内存，而且还需要一个被称为 “a guard page” 的区域用于和其他 thread 的栈空间进行隔离。线程的栈大小在可以 ulimit -s 查看或设置，也可以在 /etc/security/limits.conf 中配置，并且是固定的。而 goroutine 是动态栈，会根据需要动态地伸缩，小到 2KB 大到 1GB ，所以可以创建大量的 goroutine 。 创建销毁&emsp;&emsp;Thread 创建和销毀都会有巨大的消耗，因为要和操作系统打交道，是内核级的，通常解决的办法就是线程池。而 goroutine 因为是由 Go runtime 负责管理的，创建和销毁的消耗非常小，是用户级。 切换代价线程切换大概在几微秒级别，协程切换大概在百 ns 级别。 Thread&emsp;&emsp;线程切换过程: 进入系统调用 调度器本身代码执行 线程上下文切换: PC, SP 等寄存器，栈，线程相关的一些局部变量，还涉及一些 cache miss 的情况； 退出系统调用 &emsp;&emsp;当 threads 切换时需要保存的寄存器： &emsp;&emsp;16 general purpose registers, PC (Program Counter), SP (Stack Pointer), segment registers, 16 XMM registers, FP coprocessor state, 16 AVX registers, all MSRs etc. Goroutines&emsp;&emsp;goroutines 切换只需保存三个寄存器： &emsp;&emsp;Program Counter, Stack Pointer and BP。以及一些其它的信息，在 gobuf 结构体中。 早期的 GM 模型&emsp;&emsp;在 go 1.0 版本， 只有 GM ，而没有 P ， 只有一个全局可运行队列。 &emsp;&emsp;存在一些缺陷： 调度锁的粒度，一个全局的调度锁。创建、销毁、调度 G 都需要每个M获取锁，这就形成了激烈的锁竞争。 就绪的 G 被 M 取出执行的时候，并不一定是之前运行或创建 G 的那个 M ，这样线程局部性遭到破坏。 系统调用(CPU在M之间的切换)导致频繁的线程阻塞和取消阻塞操作增加了系统开销。 Go 内存分配类似 TCMalloc ，每个 M 都有 Thread Local Storage，每个 M 都有一些内存 cache ，只有运行的 G 的时候才需要这些 cache ，这样阻塞的 M 其实占用很大的内存。 &emsp;&emsp;后来 Go 1.1 大神 Dmitry Vyokov 增加了 P 的概念，表示执行 G 所需的资源，当 M 和 P 绑定后才能执行 G ，比如 mcache ，本地队列等。 GPM 模型&emsp;&emsp;主要的概念是： G: Goroutine，即我们在 Go 程序中使用 go 关键字创建的执行体。 M: Machine，或 worker thread，即传统意义上进程的线程； P: processor，一种执行 Go 代码被要求资源。M 必须关联一个 P 才能执行 Go 代码，但它可以被阻塞或在一个系统调用中没有关联的 P。默认为机器核数，可通过环境变量 GOMAXPROCS 设置。 &emsp;&emsp;主要优化点： mcache 从 M 移动到 P 中。 每个 P 拥有本地运行队列，新建的 G 放到本地队列，只有当本地满了再批量放入到全局队列。获取的时候优先从本地队列取。 当本地队列没有 G 的时候，会从其它的地方窃取 (findrunnable() 函数)，比如：本地队列，全局队列， netpoll ， p.runnext 等。 主要结构体&emsp;&emsp;这里涉及下主要的几个结构体。 G1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// src/runtime/runtime2.gotype g struct &#123; // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). // Stack 参数 // stack 描述了实际的栈内存：[stack.lo, stack.hi) // stackguard0 是对比 Go 栈增长的 prologue 的栈指针，如果 sp 寄存器比 stackguard0 小（由于栈往低地址方向增长），会触发栈拷贝和调度 // 通常情况下：stackguard0 = stack.lo + StackGuard，但被抢占时会变为 StackPreempt。 // stackguard1 是对比 C 栈增长的 prologue 的栈指针，当位于 g0 和 gsignal 栈上时，值为 stack.lo + StackGuard // 在其他栈上值为 ~0 用于触发 morestackc (并 crash) 调用 // // prologue (序言) 函数是函数开头的几行代码，它们准备了堆栈和寄存器以供在函数内使用。 epilogue (尾声) 函数出现在函数的末尾，并将堆栈和寄存器恢复到调用函数之前的状态。 // prologue/epilogue 参见：https://en.wikipedia.org/wiki/Function_prologue // // 编译器会在有栈溢出风险的函数开头加如 一些代码（也就是prologue），会比较 SP (栈寄存器,指向栈顶) 和 stackguard0，如果 SP 的值更小，说明当前 g 的栈要用完了， // 有溢出风险，需要调用 morestack_noctxt 函数来扩栈，morestack_noctxt()-&gt;morestack()-&gt;newstack() ，newstack中会处理抢占(preempt)。参见 asm_amd64.s,stack.go stack stack // offset known to runtime/cgo // 当前g使用的栈空间, 有lo和hi两个成员 stackguard0 uintptr // offset known to liblink // stackguard0 = stack.lo + StackGuard ，检查栈空间是否足够的值, 低于这个值会扩张栈, 用于 GO 的 stack overlow的检测 stackguard1 uintptr // offset known to liblink // stackguard1 = stack.lo + StackGuard ，检查栈空间是否足够的值, 低于这个值会扩张栈, 用于 C 的 stack overlow的检测 _panic *_panic // innermost panic - offset known to liblink // 内部 panic ，偏移量用于 liblink _defer *_defer // innermost defer // 内部 defer m *m // current m; offset known to arm liblink // 当前 g 对应的 m ; 偏移量对 arm liblink 透明 sched gobuf // goroutine 的现场，g 的调度数据, 当 g 中断时会保存当前的 pc 和 sp 等值到这里, 恢复运行时会使用这里的值 syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc // 如果 status==Gsyscall, 则 syscallsp = sched.sp 并在 GC 期间使用 syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc // 如果 status==Gsyscall, 则 syscallpc = sched.pc 并在 GC 期间使用 stktopsp uintptr // expected sp at top of stack, to check in traceback // 期望 sp 位于栈顶，用于回溯检查 param unsafe.Pointer // passed parameter on wakeup // wakeup 唤醒时候传递的参数 atomicstatus uint32 // g 的当前状态，原子性 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus // sigprof/scang锁，将会归入到atomicstatus goid int64 // goroutine ID schedlink guintptr // 下一个 g , 当 g 在链表结构中会使用 waitsince int64 // approx time when the g become blocked // g 阻塞的时间 waitreason waitReason // if status==Gwaiting // 如果 status==Gwaiting，则记录等待的原因 preempt bool // preemption signal, duplicates stackguard0 = stackpreempt // 抢占信号， g 是否被抢占中， stackguard0 = stackPreempt 的副本 paniconfault bool // panic (instead of crash) on unexpected fault address // 发生 fault panic （不崩溃）的地址 preemptscan bool // preempted g does scan for gc // 抢占式 g 会执行 GC scan gcscandone bool // g has scanned stack; protected by _Gscan bit in status // g 执行栈已经 scan 了；此此段受 _Gscan 位保护 gcscanvalid bool // false at start of gc cycle, true if G has not run since last scan; TODO: remove? // 在 gc 周期开始时为 false，如果自上次 scan 以来G没有运行，则为 true throwsplit bool // must not split stack // 必须不能进行栈分段 raceignore int8 // ignore race detection events // 忽略 race 检查事件 sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine // StartTrace 已经出发了此 goroutine 的 EvGoInSyscall sysexitticks int64 // cputicks when syscall has returned (for tracing) // 当 syscall 返回时的 cputicks（用于跟踪） traceseq uint64 // trace event sequencer // 跟踪事件排序器 tracelastp puintptr // last P emitted an event for this goroutine // 最后一个为此 goroutine 触发事件的 P lockedm muintptr // g 是否要求要回到这个 M 执行, 有的时候 g 中断了恢复会要求使用原来的 M 执行 sig uint32 // 信号，参见 defs_linux_arm64.go : siginfo writebuf []byte // 写缓存 sigcode0 uintptr // 参见 siginfo sigcode1 uintptr // 参见 siginfo sigpc uintptr // 产生信号时的PC gopc uintptr // pc of go statement that created this goroutine // 当前创建 goroutine go 语句的 pc 寄存器 ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) // 创建此 goroutine 的 ancestor (祖先) goroutine 的信息(debug.tracebackancestors 调试用) startpc uintptr // pc of goroutine function // goroutine 函数的 pc 寄存器 racectx uintptr // 竟态上下文 waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order // 如果 g 发生阻塞（且有有效的元素指针）sudog 会将当前 g 按锁住的顺序组织起来 cgoCtxt []uintptr // cgo traceback context // cgo 回溯上下文 labels unsafe.Pointer // profiler labels // 分析器标签 timer *timer // cached timer for time.Sleep // 为 time.Sleep 缓存的计时器 selectDone uint32 // are we participating in a select and did someone win the race? // 我们是否正在参与 select 且某个 goroutine 胜出 // Per-G GC state // gcAssistBytes is this G's GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. // gcAssistBytes 是该 G 在分配的字节数这一方面的的 GC 辅助 credit (信誉) // 如果该值为正，则 G 已经存入了在没有 assisting 的情况下分配了 gcAssistBytes 字节，如果该值为负，则 G 必须在 scan work 中修正这个值 // 我们以字节为单位进行追踪，一遍快速更新并检查 malloc 热路径中分配的债务（分配的字节）。assist ratio 决定了它与 scan work 债务的对应关系 gcAssistBytes int64&#125; P123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// src/runtime/runtime2.gotype p struct &#123; lock mutex // 锁 id int32 // ID status uint32 // one of pidle/prunning/... // 状态 link puintptr // p 的链表 schedtick uint32 // incremented on every scheduler call // 每次调度程序调用时增加 syscalltick uint32 // incremented on every system call // 每次系统调用时增加 sysmontick sysmontick // last tick observed by sysmon // sysmon观察到的最后一个tick，会记录 m muintptr // back-link to associated m (nil if idle) // 反向链接到相关的M（如果空闲则为nil） mcache *mcache // mcache: 每个P的内存缓存，不需要加锁 racectx uintptr // 竟态上下文 deferpool [5][]*_defer // pool of available defer structs of different sizes (see panic.go) // defer池，拥有不同的尺寸 deferpoolbuf [5][32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. // goroutine ID的缓存将分摊对runtime.sched.goidgen的访问。 goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. // 可运行goroutine队列。 无锁访问。 // runqhead 和 runqtail 都是 uint32 ，不用担心越界问题，超过最大值之后，会变为 0 ，并且 0 - ^uint32(0) = 1 ，也就是说取长度也不会有问题。 runqhead uint32 // 队头，runqhead 在后头跟，指向第一个可以使用，应该从这里取出 runqtail uint32 // 队尾，runqtail 在队列前面走，指向第一个空槽，应该插入到这里 runq [256]guintptr // 运行队列 // runnext, if non-nil, is a runnable G that was ready'd by // the current G and should be run next instead of what's in // runq if there's time remaining in the running G's time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready'd // goroutines to the end of the run queue. // runnext（如果不是nil）是当前G准备好的可运行G，如果正在运行的G的时间片中还有剩余时间，则应在下一个运行，而不是在runq中的G来运行。 // 它将继承当前时间片中剩余的时间。如果将一组goroutine锁定为“通信等待”模式，则将其设置为一个单元进行调度，并消除了（可能较大的）调度 // 延迟，而这种延迟可能是由于将就绪的goroutine添加到运行队列的末尾而引起的。 runnext guintptr // Available G's (status == Gdead) // 可用的G，状态为Gdead gFree struct &#123; gList n int32 &#125; sudogcache []*sudog // sudog缓存，初始化为： sudogbuf[:0] sudogbuf [128]*sudog tracebuf traceBufPtr // trace缓存，64Kb // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. // traceSweep指示清扫事件是否被trace。这用于推迟清扫开始事件，直到实际扫过一个span为止。 traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. // traceSwept和traceReclaimed跟踪通过在当前清扫循环中进行清扫来清除和回收的字节数。 traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex // 分配器，每个P一个，避免加锁 // Per-P GC state // 每个P的GC状态 gcAssistTime int64 // Nanoseconds in assistAlloc // gcAassistAlloc中计时 gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker // GC Mark计时 gcBgMarkWorker guintptr // 标记G gcMarkWorkerMode gcMarkWorkerMode // 标记模式 // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // mark worker启动时间 // gcw is this P's GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. // gcw是此P的GC工作缓冲区高速缓存。工作缓冲区由写屏障填充，由辅助mutator(赋值器)耗尽，并放置在某些GC状态转换上。 gcw gcWork // GC 的本地工作队列，灰色对象管理 // wbBuf is this P's GC write barrier buffer. // // TODO: Consider caching this in the running G. // wbBuf 是当前 P 的 GC 的 write barrier 缓存 wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point // 如果为 1, 则在下一个 safe-point 运行 sched.safePointFn pad cpu.CacheLinePad&#125; gobuf1234567891011// src/runtime/runtime2.go// gobuf记录与协程切换相关信息type gobuf struct &#123; sp uintptr // sp 寄存器 pc uintptr // pc 寄存器 g guintptr // g 指针 ctxt unsafe.Pointer // 这个似乎是用来辅助 gc 的 ret sys.Uintreg // 作用 ？ panic.go 中 recovery 函数有设置为 1 lr uintptr // 这是在 arm 上用的寄存器，不用关心 bp uintptr // for GOEXPERIMENT=framepointer // 开启 GOEXPERIMENT=framepointer ，才会有这个&#125; M123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// src/runtime/runtime2.gotype m struct &#123; g0 *g // goroutine with scheduling stack // 用于执行调度指令的 goroutine， 用于调度的特殊 g , 调度和执行系统调用时会切换到这个 g morebuf gobuf // gobuf arg to morestack // morestack 的 gobuf 参数 divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. // debugger 不知道的字段 procid uint64 // for debuggers, but offset not hard-coded // 用于 debugger，偏移量不是写死的 gsignal *g // signal-handling g // 用于 debugger，偏移量不是写死的 goSigStack gsignalStack // Go-allocated signal handling stack // Go 分配的 signal handling 栈 sigmask sigset // storage for saved signal mask // 用于保存 saved signal mask tls [6]uintptr // thread-local storage (for x86 extern register) // thread-local storage (对 x86 而言为额外的寄存器) mstartfn func() // M启动函数 curg *g // current running goroutine // 当前运行的用户 g caughtsig guintptr // goroutine running during fatal signal // goroutine 在 fatal signal 中运行 p puintptr // attached p for executing go code (nil if not executing go code) // 执行 go 代码时持有的 p (如果没有执行则为 nil) nextp puintptr // 下一个p， 唤醒 M 时, M 会拥有这个 P oldp puintptr // the p that was attached before executing a syscall // 执行系统调用之前绑定的 p id int64 // ID mallocing int32 // 是否正在分配内存 throwing int32 // 是否正在抛出异常 preemptoff string // if != "", keep curg running on this m // 如果不为空串 ""，继续让当前 g 运行在该 M 上 locks int32 // M的锁 dying int32 // 是否正在死亡，参见startpanic_m profilehz int32 // cpu profiling rate spinning bool // m is out of work and is actively looking for work // m 当前没有运行 work 且正处于寻找 work 的活跃状态 blocked bool // m is blocked on a note // m 阻塞在一个 note 上 inwb bool // m is executing a write barrier // m 在执行write barrier newSigstack bool // minit on C thread called sigaltstack // C 线程上的 minit 是否调用了 signalstack printlock int8 // print 锁，参见 print.go printlock/printunlock incgo bool // m is executing a cgo call // m 正在执行 cgo 调用 freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) // 如果为 0，安全的释放 g0 并删除 m (原子操作) fastrand [2]uint32 // 快速随机 needextram bool // 需要额外的 m traceback uint8 // 回溯 ncgocall uint64 // number of cgo calls in total // 总共的 cgo 调用数 ncgo int32 // number of cgo calls currently in progress // 正在进行的 cgo 调用数 cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily // 如果非零，则表示 cgoCaller 正在临时使用 cgoCallers *cgoCallers // cgo traceback if crashing in cgo call // cgo 调用崩溃的 cgo 回溯 park note // M 休眠时使用的信号量, 唤醒 M 时会通过它唤醒 alllink *m // on allm // 在 allm 上，将所有的 m 链接起来 schedlink muintptr // 下一个 m , 当 m 在链表结构中会使用 mcache *mcache // 分配内存时使用的本地分配器, 和 p.mcache 一样(拥有 P 时会复制过来) lockedg guintptr // 表示与当前 M 锁定的那个 G 。运行时系统会把 一个 M 和一个 G 锁定，一旦锁定就只能双方相互作用，不接受第三者。g.lockedm 的对应值 createstack [32]uintptr // stack that created this thread.// 当前线程创建的栈 lockedExt uint32 // tracking for external LockOSThread // 外部 LockOSThread 追踪，LockOSThread/UnlockOSThread lockedInt uint32 // tracking for internal lockOSThread // 内部 lockOSThread 追踪，lockOSThread/unlockOSThread nextwaitm muintptr // next m waiting for lock // 内部 lockOSThread 追踪 waitunlockf unsafe.Pointer // todo go func(*g, unsafe.pointer) bool // 参见proc.go gopark waitlock unsafe.Pointer // 参见proc.go gopark waittraceev byte // 参见proc.go gopark waittraceskip int // 参见proc.go gopark startingtrace bool // 开始trace，见trace.go StartTrace syscalltick uint32 // 每次系统调用时增加 thread uintptr // thread handle // 线程句柄 freelink *m // on sched.freem // 在 sched.freem 上 // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. // 下面这些字段因为它们太大而不能放在低级的 NOSPLIT 函数的堆栈上。 libcall libcall // 调用信息 libcallpc uintptr // for cpu profiler // 用于 cpu profiler libcallsp uintptr // libcall SP libcallg guintptr // libcall G syscall libcall // stores syscall parameters on windows // 存储 windows 上系统调用的参数 vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call mOS&#125; schedt1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// src/runtime/runtime2.gotype schedt struct &#123; // accessed atomically. keep at top to ensure alignment on 32-bit systems. // 原子访问，放到顶部，确保在32位系统上对齐（8字节）。 goidgen uint64 // go runtime ID生成器，原子自增，在newproc1和oneNewExtraM中使用了 lastpoll uint64 // 上一次轮询的时间（nanotime） lock mutex // 锁 // When increasing nmidle, nmidlelocked, nmsys, or nmfreed, be // sure to call checkdead(). // 当增加nmidle，nmidlelocked，nmsys或nmfreed时，请确保调用checkdead()。 midle muintptr // idle m's waiting for work // 空闲的 M 队列 nmidle int32 // number of idle m's waiting for work // 当前等待工作的空闲 M 计数 nmidlelocked int32 // number of locked m's waiting for work // 当前等待工作的被 lock 的 M 计数 mnext int64 // number of m's that have been created and next M ID // 已经被创建的 M 的数量，下一个 M 的 ID maxmcount int32 // maximum number of m's allowed (or die) // 最大M的数量 nmsys int32 // number of system m's not counted for deadlock // 系统 M 的数量， 在 deadlock 中不计数 nmfreed int64 // cumulative number of freed m's // 释放的 M 的累计数量 ngsys uint32 // number of system goroutines; updated atomically // 系统调用 goroutine 的数量，原子更新 pidle puintptr // idle p's // 空闲的P npidle uint32 // 空闲的P的数目 nmspinning uint32 // See "Worker thread parking/unparking" comment in proc.go. // 处于spinning的M的数目 // Global runnable queue. runq gQueue // 全局的 G 运行队列 runqsize int32 // 全局的 G 运行队列大小 // disable controls selective disabling of the scheduler. // // Use schedEnableUser to control this. // // disable is protected by sched.lock. // disable控制选择性禁用调度程序。使用schedEnableUser进行控制。受sched.lock保护。 disable struct &#123; // user disables scheduling of user goroutines. user bool // 用户禁用用户的goroutines调度 runnable gQueue // pending runnable Gs // 等待的可运行的G队列 n int32 // length of runnable // runnable的长度 &#125; // Global cache of dead G's. // dead G全局缓存，已退出的 goroutine 对象缓存下来，避免每次创建 goroutine 时都重新分配内存，可参考proc.go中的gfput,gfget gFree struct &#123; lock mutex // 锁 stack gList // Gs with stacks // 有堆栈的G noStack gList // Gs without stacks // 没有堆栈的G n int32 // stack和noStack中的总数 &#125; // Central cache of sudog structs. sudoglock mutex // sudog缓存的锁 sudogcache *sudog // sudog缓存 // Central pool of available defer structs of different sizes. deferlock mutex // defer缓存的锁 deferpool [5]*_defer // defer缓存 // freem is the list of m's waiting to be freed when their // m.exited is set. Linked through m.freelink. freem *m // freem是设置 m.exited 时等待释放的 m 列表。通过 m.freelink 链接。 gcwaiting uint32 // gc is waiting to run // GC等待运行 stopwait int32 // 需要停止P的数目 stopnote note // stopwait睡眠唤醒事件 sysmonwait uint32 // 等待系统监控 sysmonnote note // sysmonwait睡眠唤醒事件 // safepointFn should be called on each P at the next GC // safepoint if p.runSafePointFn is set. // 如果设置了p.runSafePointFn，则应在下一个GC安全点的每个P上调用safepointFn。 safePointFn func(*p) // 安全点函数 safePointWait int32 // 等待safePointFn执行 safePointNote note // safePointWait睡眠唤醒事件 profilehz int32 // cpu profiling rate // CPU procresizetime int64 // nanotime() of last change to gomaxprocs // 上一次修改gomaxprocs的时间，参见proc.go中的procresize totaltime int64 // ∫gomaxprocs dt up to procresizetime // 总时间&#125; Global objects12345678910111213// src/runtime/runtime2.go// 全局的一些对象var ( allglen uintptr // 所有G的数目 allm *m // 所有的M allp []*p // len(allp) == gomaxprocs; may change at safe points, otherwise immutable // 可能在安全区更改，否则不变 allpLock mutex // Protects P-less reads of allp and all writes // allp的锁 gomaxprocs int32 // GOMAXPROCS ncpu int32 // CPU数目 forcegc forcegcstate // 强制GC sched schedt // 调度 newprocs int32 // GOMAXPROCS函数设置，startTheWorld处理) 12345// src/runtime/proc.govar ( m0 m // 主M，asm_amd64.s中runtime·rt0_go初始化 g0 g // 主G，asm_amd64.s中runtime·rt0_go初始化) 结束语&emsp;&emsp;这里主要介绍 GPM 的一些基础概念。下一篇，将介绍 GMP 的调度。]]></content>
      <categories>
        <category>【golang源码分析】</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【golang源码分析】之内存管理]]></title>
    <url>%2F2019%2F09%2F11%2F%E3%80%90golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%E4%B9%8B%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"></content>
      <categories>
        <category>【golang源码分析】</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-hello-world]]></title>
    <url>%2F2019%2F09%2F10%2Fkubernetes-hello-world%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;记录一下以前给公司员工kubernetes的入门培训 kubernetes-hello-world &emsp;&emsp;从基础知识到实战讲解kubernetes。实现了一个简单的类似浏览器访问量的功能（只是注重对kubernetes的了解）。详情请访问kubernetes-hello-world。]]></content>
      <categories>
        <category>kubernetes</category>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【golang源码分析】之启动追踪]]></title>
    <url>%2F2019%2F09%2F05%2F%E3%80%90golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%E4%B9%8B%E5%90%AF%E5%8A%A8%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;很多人也许对Go代码是怎么启动的比较感兴趣， 我也不例外。 因此在这里调试下代码， 看看到底是怎么启动的， 并在此做下记录, 暂时不会逐行分析，只是了解下Go的启动流程。（关于环境，在第一篇【golang源码分析】之源码结构中已经提到过， 如无特殊说明后续相关的都是基于此环境，不再提及。） 安装go1.12.9&emsp;&emsp;应为需要调试源代码，所以这里源码安装go， 并禁止优化和内联。我是ubuntu18.04环境，其他环境类似。 &emsp;&emsp;这里采用了docker来安装， github地址go-src-debug-docker, 并且镜像已经推到hub上面了go-src-debug。 123456# 启动docker# 如果需要映射卷的， 请加上-v选项# 这里需要给--privileged， 不然gdb有问题docker run -it -d --privileged --name go-src-debug veezhanggo-src-debug:1.12.9# 进入dockerdocker exec -it go-src-debug bash &emsp;&emsp;注： 如无特殊说明，后续的调试都是在docker下执行。 调试代码样例&emsp;&emsp;这里写了一个简单的代码(main.go)来进行启动追踪， 如下： 123456789package mainimport ( "fmt")func main()&#123; fmt.Println("Hello, I'm Vee Zhang.")&#125; 编译&emsp;&emsp;Go打包的程序和C打包的程序一样在linux系统上是 elf 格式的。编译参数我们添加了 -gcflags 编译参数， 编译命令如下： 123456# -N disable optimizations 禁止优化# -l disable inlining 禁止内联go build -gcflags "-N -l" -o main main.go# 执行下，看看是否正常./mainHello, I'm Vee Zhang. 调试&emsp;&emsp;使用 gdb 进行调试， 由于添加了部分注释，可能会导致gdb行号对不上。 1234567891011121314151617181920212223242526gdb ./mainGNU gdb (Ubuntu 8.1-0ubuntu3) 8.1.0.20180409-gitCopyright (C) 2018 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word"...Reading symbols from ./main...done.warning: File "go/src/runtime/runtime-gdb.py" auto-loading has been declined by your `auto-load safe-path' set to "$debugdir:$datadir/auto-load".To enable execution of this file add add-auto-load-safe-path go/src/runtime/runtime-gdb.pyline to your configuration file "/root/.gdbinit".To completely disable this security protection add set auto-load safe-path /line to your configuration file "/root/.gdbinit".For more information about this security protection see the"Auto-loading safe path" section in the GDB manual. E.g., run from the shell: info "(gdb)Auto-loading safe path" &emsp;&emsp;在gdb命令行输入： info files， 可以看到main的Entry point。 12345678910111213141516(gdb) info filesSymbols from "/main".Local exec file: `/main', file type elf64-x86-64. Entry point: 0x452890 0x0000000000401000 - 0x0000000000487304 is .text 0x0000000000488000 - 0x00000000004d2ac0 is .rodata 0x00000000004d2c60 - 0x00000000004d3834 is .typelink 0x00000000004d3838 - 0x00000000004d3880 is .itablink 0x00000000004d3880 - 0x00000000004d3880 is .gosymtab 0x00000000004d3880 - 0x00000000005433e6 is .gopclntab 0x0000000000544000 - 0x0000000000550a9c is .noptrdata 0x0000000000550aa0 - 0x0000000000557790 is .data 0x00000000005577a0 - 0x0000000000572ef0 is .bss 0x0000000000572f00 - 0x0000000000575658 is .noptrbss 0x0000000000400f9c - 0x0000000000401000 is .note.go.buildid &emsp;&emsp;在Entry point的指针上打算断点b *0x452890, 并启动。 1234567(gdb) b *0x452890Breakpoint 1 at 0x452890: file go/src/runtime/rt0_linux_amd64.s, line 8.(gdb) rStarting program: /mainBreakpoint 1, _rt0_amd64_linux () at go/src/runtime/rt0_linux_amd64.s:88 JMP _rt0_amd64(SB) &emsp;&emsp;可以看到，该断点在文件go/src/runtime/rt0_linux_amd64.s的第8行， 我们打开看看 123456789101112// Copyright 2009 The Go Authors. All rights reserved.// Use of this source code is governed by a BSD-style// license that can be found in the LICENSE file.#include "textflag.h"// linux amd64 系统的启动函数TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8 JMP _rt0_amd64(SB) // 跳转到_rt0_amd64函数， 在 asm_amd64.s 中。TEXT _rt0_amd64_linux_lib(SB),NOSPLIT,$0 JMP _rt0_amd64_lib(SB) &emsp;&emsp;注： 不同的平台有不同的程序入口, 如下： 123456789101112131415161718192021222324252627282930313233343536373839go/src/runtime/rt0_aix_ppc64.sgo/src/runtime/rt0_android_386.sgo/src/runtime/rt0_android_amd64.sgo/src/runtime/rt0_android_arm.sgo/src/runtime/rt0_android_arm64.sgo/src/runtime/rt0_darwin_386.sgo/src/runtime/rt0_darwin_amd64.sgo/src/runtime/rt0_darwin_arm.sgo/src/runtime/rt0_darwin_arm64.sgo/src/runtime/rt0_dragonfly_amd64.sgo/src/runtime/rt0_freebsd_386.sgo/src/runtime/rt0_freebsd_amd64.sgo/src/runtime/rt0_freebsd_arm.sgo/src/runtime/rt0_js_wasm.sgo/src/runtime/rt0_linux_386.sgo/src/runtime/rt0_linux_amd64.sgo/src/runtime/rt0_linux_arm.sgo/src/runtime/rt0_linux_arm64.sgo/src/runtime/rt0_linux_mips64x.sgo/src/runtime/rt0_linux_mipsx.sgo/src/runtime/rt0_linux_ppc64.sgo/src/runtime/rt0_linux_ppc64le.sgo/src/runtime/rt0_linux_s390x.sgo/src/runtime/rt0_nacl_386.sgo/src/runtime/rt0_nacl_amd64p32.sgo/src/runtime/rt0_nacl_arm.sgo/src/runtime/rt0_netbsd_386.sgo/src/runtime/rt0_netbsd_amd64.sgo/src/runtime/rt0_netbsd_arm.sgo/src/runtime/rt0_openbsd_386.sgo/src/runtime/rt0_openbsd_amd64.sgo/src/runtime/rt0_openbsd_arm.sgo/src/runtime/rt0_plan9_386.sgo/src/runtime/rt0_plan9_amd64.sgo/src/runtime/rt0_plan9_arm.sgo/src/runtime/rt0_solaris_amd64.sgo/src/runtime/rt0_windows_386.sgo/src/runtime/rt0_windows_amd64.sgo/src/runtime/rt0_windows_arm.s &emsp;&emsp;从go/src/runtime/rt0_linux_amd64.s文件我们可以知道，跳转到_rt0_amd64了， 再设置断点， 并继续调试： 1234567(gdb) b _rt0_amd64Breakpoint 2 at 0x44ef70: file go/src/runtime/asm_amd64.s, line 15.(gdb) cContinuing.Breakpoint 2, _rt0_amd64 () at go/src/runtime/asm_amd64.s:1515 MOVQ 0(SP), DI // argc &emsp;&emsp;接着打开go/src/runtime/asm_amd64.s文件： 12345678910111213141516171819// Copyright 2009 The Go Authors. All rights reserved.// Use of this source code is governed by a BSD-style// license that can be found in the LICENSE file.#include "go_asm.h"#include "go_tls.h"#include "funcdata.h"#include "textflag.h"// _rt0_amd64 is common startup code for most amd64 systems when using// internal linking. This is the entry point for the program from the// kernel for an ordinary -buildmode=exe program. The stack holds the// number of arguments and the C-style argv.// _rt0_amd64 是使用内部链接时大多数amd64系统的通用启动代码。 这是内核中普通 -buildmode=exe 程序的入口点。// 栈保存了参数的数量以及 C 风格的 argvTEXT _rt0_amd64(SB),NOSPLIT,$-8 MOVQ 0(SP), DI // argc // 设置参数argc LEAQ 8(SP), SI // argv // 设置参数argv JMP runtime·rt0_go(SB) // 跳转到runtime·rt0_go &emsp;&emsp;从go/src/runtime/asm_amd64.s文件我们可以知道，设置参数后跳转到runtime·rt0_go了， 再设置断点： &emsp;&emsp;注意： 断点设置为runtime.rt0_go, 中间的 · 换成下面的 .， 下同 。 1234567(gdb) b runtime.rt0_goBreakpoint 3 at 0x44ef80: file go/src/runtime/asm_amd64.s, line 89.(gdb) cContinuing.Breakpoint 3, runtime.rt0_go () at go/src/runtime/asm_amd64.s:8989 MOVQ DI, AX // argc &emsp;&emsp;可以看到，还在文件go/src/runtime/asm_amd64.s中， 定义在87行, 如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153TEXT runtime·rt0_go(SB),NOSPLIT,$0 // copy arguments forward on an even stack // 将参数向前复制到一个偶数栈上 MOVQ DI, AX // argc // 获取之前设置的argc参数 MOVQ SI, BX // argv // 获取之前设置的argv参数 SUBQ $(4*8+7), SP // 2args 2auto ANDQ $~15, SP // 字节对齐 MOVQ AX, 16(SP) MOVQ BX, 24(SP) // create istack out of the given (operating system) stack. // _cgo_init may update stackguard. // 从给定（操作系统）栈中创建 istack 。 _cgo_init 可能更新 stackguard // runtime.g0 位于 runtime/proc.go // 初始化 g0，g0 的栈实际上就是 linux 分配的栈，大约 64k。 MOVQ $runtime·g0(SB), DI // DI = runtime·g0 LEAQ (-64*1024+104)(SP), BX // BX = SP-64*1024+104 MOVQ BX, g_stackguard0(DI) // g0.stackguard0 = SP-64*1024+104 MOVQ BX, g_stackguard1(DI) // g0.stackguard1 = g0.stackguard0 MOVQ BX, (g_stack+stack_lo)(DI) // g0.stack.lo = g0.stackguard0 MOVQ SP, (g_stack+stack_hi)(DI) // g0.stack.hi = SP // find out information about the processor we're on // 寻找正在运行的处理器信息 MOVL $0, AX // AX = 0 ，CPUID 参数？ CPUID // CPUID 会设置 AX ， BX ， CX ， DX 的值 MOVL AX, SI // SI = AX ， 保存 CPU 信息 CMPL AX, $0 // 如果没有获取到 JE nocpuinfo // 跳转到 nocpuinfo // Figure out how to serialize RDTSC. // On Intel processors LFENCE is enough. AMD requires MFENCE. // Don't know about the rest, so let's do MFENCE. // 处理如何序列化 RDTSC 。在 intel 处理器上， LFENCE 足够了。 AMD 则需要 MFENCE。 其他处理器的情况不清楚，所以让用 MFENCE。 // 判断是否是 intel cpu CMPL BX, $0x756E6547 // "Genu" JNE notintel CMPL DX, $0x49656E69 // "ineI" JNE notintel CMPL CX, $0x6C65746E // "ntel" JNE notintel MOVB $1, runtime·isIntel(SB) // 设置是否是 intel cpu ，在 proc.go 中。 MOVB $1, runtime·lfenceBeforeRdtsc(SB) // 设置是否在 RDTSC 指令之前是否需要 LFENCE 指令。否则是 MFENCE 指令。notintel: // Load EAX=1 cpuid flags MOVL $1, AX // AX = 1 ，CPUID 参数？ CPUID // 获取 cpu flags MOVL AX, runtime·processorVersionInfo(SB)// 设置 processorVersionInfonocpuinfo: // if there is an _cgo_init, call it. // 如果有 _cgo_init ，就执行 MOVQ _cgo_init(SB), AX // TEST 对两个参数(目标，源)执行 AND 逻辑操作，并根据结果设置标志寄存器 (ZF)，结果本身不会保存。 // ZF(Zero Flag) 零标志，运算结果为0时置1，否则置0。 TESTQ AX, AX JZ needtls // jump if zero，也就是 AX AND AX == 0 （ _cgo_init 返回 0 ），则跳转到 needtls // g0 already in DI // 这里的 DI 就是上面初始化 g0 时设置的 g0 的地址 MOVQ DI, CX // Win64 uses CX for first parameter MOVQ $setg_gcc&lt;&gt;(SB), SI CALL AX // update stackguard after _cgo_init // _cgo_init 后更新 stackguard MOVQ $runtime·g0(SB), CX // CX = g0 MOVQ (g_stack+stack_lo)(CX), AX // AX = g0.stack.lo ADDQ $const__StackGuard, AX // AX += const__StackGuard , stack.go 中定义 MOVQ AX, g_stackguard0(CX) // g0.stackguard0 = AX = g0.stack.lo + const__StackGuard MOVQ AX, g_stackguard1(CX) // g0.stackguard1 = AX = g0.stack.lo + const__StackGuard#ifndef GOOS_windows JMP ok // Windows 跳转到 ok#endifneedtls:#ifdef GOOS_plan9 // skip TLS setup on Plan 9 JMP ok // Plan 9 跳转到 ok#endif#ifdef GOOS_solaris // skip TLS setup on Solaris JMP ok // GOOS_solaris 跳转到 ok#endif#ifdef GOOS_darwin // skip TLS setup on Darwin JMP ok // GOOS_darwin 跳转到 ok#endif // 设置tls， Thread Local Storage LEAQ runtime·m0+m_tls(SB), DI // DI = m0.tls ，这个会在 runtime·settls 中使用 CALL runtime·settls(SB) // 调用 runtime·settls, settls 函数的参数在DI寄存器中 // store through it, to make sure it works // get_tls 和 g 是宏，位于 runtime/go_tls.h // #define get_tls(r) MOVQ TLS, r // #define g(r) 0(r)(TLS*1) // 此处对 tls 进行了一次测试，确保值正确写入了 m0.tls get_tls(BX) // 等价于 MOVQ TLS, BX 。 从 TLS 起始移动 8 byte 值到 BX 寄存器，获取 fs 段基地址并放入 BX 寄存器，其实就是 m0.tls[1] 的地址 MOVQ $0x123, g(BX) // 0(BX)(TLS*1) = $0x123 ，0x123拷贝到fs段基地址偏移-8的内存位置，也就是m0.tls[0] =0x123 MOVQ runtime·m0+m_tls(SB), AX // AX = m0.tls[0] CMPQ AX, $0x123 // 比较 AX == $0x123 JEQ 2(PC) // 如果相等，跳转下面 2 条指令，也就是 ok 后 CALL runtime·abort(SB) // 检测失败ok: // set the per-goroutine and per-mach "registers" // 将 g0 放到 tls 里，这里实际上就是 m0.tls get_tls(BX) // 等价于 MOVQ TLS, BX 。 从 TLS 起始移动 8 byte 值到 BX 寄存器，获取 fs 段基地址并放入 BX 寄存器，其实就是 m0.tls[1] 的地址 LEAQ runtime·g0(SB), CX // CX=g0 MOVQ CX, g(BX) // 等价于 MOVQ CX， 0(BX)(TLS*1), 把g0存到TLS LEAQ runtime·m0(SB), AX // AX=m0 // save m-&gt;g0 = g0 MOVQ CX, m_g0(AX) // m0.g0 = g0 // save m0 to g0-&gt;m MOVQ AX, g_m(CX) // g0.m = m0 CLD // convention is D is always left cleared // 这个函数检查了各种类型以及类型转换是否有问题 CALL runtime·check(SB) MOVL 16(SP), AX // copy argc // AX = argc MOVL AX, 0(SP) // 设置后面 runtime·args 调用的第一个参数 MOVQ 24(SP), AX // copy argv // AX = argv MOVQ AX, 8(SP) // 设置后面 runtime·args 调用的第二个参数 CALL runtime·args(SB) // 设置参数 ， 函数原型： func args(c int32, v **byte) ， 在 runtime1.go CALL runtime·osinit(SB) // 初始化 os ，在 os_linux.go CALL runtime·schedinit(SB) // 初始化 sched ，在 proc.go // create a new goroutine to start program // 创建 goroutine 并加入到等待队列，该 goroutine 执行 runtime.mainPC 所指向的函数 MOVQ $runtime·mainPC(SB), AX // entry// 入口函数 在 proc.go 中 PUSHQ AX // 压栈，设置参数 runtime·newproc 的 fn PUSHQ $0 // arg size // 压栈，设置参数 runtime·newproc 的 siz CALL runtime·newproc(SB) // 调用 runtime·newproc ，在 proc.go 函数原型： func newproc(siz int32, fn *funcval) POPQ AX // 弹出 PUSHQ $0 POPQ AX // 弹出 PUSHQ AX // start this M CALL runtime·mstart(SB) // 启动调度程序，调度到刚刚创建的 goroutine 执行，在 proc.go 函数原型： func mstart() CALL runtime·abort(SB) // mstart should never return // mstart 永远不会返回 RET // Prevent dead-code elimination of debugCallV1, which is // intended to be called by debuggers. // 防止调试程序要调用的 debugCallV1 消除死代码。 MOVQ $runtime·debugCallV1(SB), AX // AX = runtime·debugCallV1 RET// 声明全局的变量 mainPC 为 runtime.main 函数的地址，该变量为 read onlyDATA runtime·mainPC+0(SB)/8,$runtime·main(SB)GLOBL runtime·mainPC(SB),RODATA,$8 &emsp;&emsp; 在上面我们看到会调用runtime·check, runtime·args, runtime·osinit， runtime·schedinit， runtime·mainPC， runtime·newproc， runtime·mstart， runtime·abort 等等几个函数， 这些就是Go启动的重要函数。 &emsp;&emsp; 从上面可以看到会调用到runtime.mainPC， 而runtime.mainPC即是runtime·main的地址， 那么最终就会调用到runtime·main， 我们查看runtime.main（在go/src/runtime/proc.go中）的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145// The main goroutine.// 主 goroutine，也就是runtime·mainPCfunc main() &#123; // 获取当前的G, G为TLS(Thread Local Storage) g := getg() // Racectx of m0-&gt;g0 is used only as the parent of the main goroutine. // It must not be used for anything else. // m0-&gt;g0 的racectx仅用作主 goroutine的父代。不得将其用于其他任何用途。 g.m.g0.racectx = 0 // Max stack size is 1 GB on 64-bit, 250 MB on 32-bit. // Using decimal instead of binary GB and MB because // they look nicer in the stack overflow failure message. // 执行栈的最大限制： 1GB on 64-bit， 250 MB on 32-bit。使用十进制而不是二进制GB和MB，因为它们在堆栈溢出失败消息中好看些。 if sys.PtrSize == 8 &#123; maxstacksize = 1000000000 &#125; else &#123; maxstacksize = 250000000 &#125; // Allow newproc to start new Ms. // 标示main goroutine启动了，接下来允许 newproc 启动新的 m mainStarted = true if GOARCH != "wasm" &#123; // no threads on wasm yet, so no sysmon // 1.11 新引入的 web assembly, 目前 wasm 不支持线程，无系统监控 // 启动系统后台监控 (定期 GC，并发任务调度) systemstack(func() &#123; newm(sysmon, nil) &#125;) &#125; // Lock the main goroutine onto this, the main OS thread, // during initialization. Most programs won't care, but a few // do require certain calls to be made by the main thread. // Those can arrange for main.main to run in the main thread // by calling runtime.LockOSThread during initialization // to preserve the lock. // 将主 goroutine 锁在主 OS 线程下进行初始化工作。大部分程序并不关心这一点，但是有一些图形库（基本上属于 cgo 调用）会要求在主线程下进行初始化工作。 // 即便是在 main.main 下仍然可以通过公共方法 runtime.LockOSThread 来强制将一些特殊的需要主 OS 线程的调用锁在主 OS 线程下执行初始化 lockOSThread() // 执行 runtime.main 函数的 G 必须是绑定在 m0 上的 if g.m != &amp;m0 &#123; throw("runtime.main not on m0") &#125; // 执行初始化运行时 runtime_init() // must be before defer // defer 必须在此调用结束后才能使用 if nanotime() == 0 &#123; throw("nanotime returning zero") &#125; // Defer unlock so that runtime.Goexit during init does the unlock too. // 延迟解锁，以便init期间的runtime.Goexit也会执行解锁。 needUnlock := true defer func() &#123; if needUnlock &#123; unlockOSThread() &#125; &#125;() // Record when the world started. // 记录程序的启动时间 runtimeInitTime = nanotime() // 启动垃圾回收器后台操作 gcenable() main_init_done = make(chan bool) if iscgo &#123; if _cgo_thread_start == nil &#123; throw("_cgo_thread_start missing") &#125; if GOOS != "windows" &#123; if _cgo_setenv == nil &#123; throw("_cgo_setenv missing") &#125; if _cgo_unsetenv == nil &#123; throw("_cgo_unsetenv missing") &#125; &#125; if _cgo_notify_runtime_init_done == nil &#123; throw("_cgo_notify_runtime_init_done missing") &#125; // Start the template thread in case we enter Go from // a C-created thread and need to create a new thread. // 启动模板线程来处理从 C 创建的线程进入 Go 时需要创建一个新的线程的情况。 startTemplateThread() cgocall(_cgo_notify_runtime_init_done, nil) &#125; // 执行 main_init，进行间接调用，因为链接器在设定运行时的时候不知道 main 包的地址 fn := main_init // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime fn() close(main_init_done) needUnlock = false unlockOSThread() // 如果是基础库则不需要执行 main 函数了 if isarchive || islibrary &#123; // A program compiled with -buildmode=c-archive or c-shared // has a main, but it is not executed. // 使用-buildmode=c-archive或c-shared编译的程序具有main函数，但不会执行。 return &#125; // 执行用户 main 包中的 main 函数，处理为非间接调用，因为链接器在设定运行时不知道 main 包的地址 fn = main_main // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime fn() // race 相关 if raceenabled &#123; racefini() &#125; // Make racy client program work: if panicking on // another goroutine at the same time as main returns, // let the other goroutine finish printing the panic trace. // Once it does, it will exit. See issues 3934 and 20018.\ // 使客户端程序正常工作：如果在其他 goroutine 上 panic 、与此同时 main 返回，也让其他 goroutine 能够完成 panic trace 的打印。打印完成后，立即退出。 // 见 issue 3934 和 20018 if atomic.Load(&amp;runningPanicDefers) != 0 &#123; // Running deferred functions should not take long. // 运行 defer 函数应该不会花太长时间。 for c := 0; c &lt; 1000; c++ &#123; if atomic.Load(&amp;runningPanicDefers) == 0 &#123; break &#125; Gosched() &#125; &#125; if atomic.Load(&amp;panicking) != 0 &#123; gopark(nil, nil, waitReasonPanicWait, traceEvGoStop, 1) &#125; // 退出执行，返回退出状态码 exit(0) // 如果 exit 没有被正确实现，则下面的代码能够强制退出程序，因为 *nil (nil deref) 会崩溃。 for &#123; var x *int32 *x = 0 &#125;&#125; &emsp;&emsp;接下来把其它几个函数看看： runtime·check(go/src/runtime/runtime1.go) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156// 做一些数据检测func check() &#123; var ( a int8 b uint8 c int16 d uint16 e int32 f uint32 g int64 h uint64 i, i1 float32 j, j1 float64 k unsafe.Pointer l *uint16 m [4]byte ) type x1t struct &#123; x uint8 &#125; type y1t struct &#123; x1 x1t y uint8 &#125; var x1 x1t var y1 y1t if unsafe.Sizeof(a) != 1 &#123; throw("bad a") &#125; if unsafe.Sizeof(b) != 1 &#123; throw("bad b") &#125; if unsafe.Sizeof(c) != 2 &#123; throw("bad c") &#125; if unsafe.Sizeof(d) != 2 &#123; throw("bad d") &#125; if unsafe.Sizeof(e) != 4 &#123; throw("bad e") &#125; if unsafe.Sizeof(f) != 4 &#123; throw("bad f") &#125; if unsafe.Sizeof(g) != 8 &#123; throw("bad g") &#125; if unsafe.Sizeof(h) != 8 &#123; throw("bad h") &#125; if unsafe.Sizeof(i) != 4 &#123; throw("bad i") &#125; if unsafe.Sizeof(j) != 8 &#123; throw("bad j") &#125; if unsafe.Sizeof(k) != sys.PtrSize &#123; throw("bad k") &#125; if unsafe.Sizeof(l) != sys.PtrSize &#123; throw("bad l") &#125; if unsafe.Sizeof(x1) != 1 &#123; throw("bad unsafe.Sizeof x1") &#125; if unsafe.Offsetof(y1.y) != 1 &#123; throw("bad offsetof y1.y") &#125; if unsafe.Sizeof(y1) != 2 &#123; throw("bad unsafe.Sizeof y1") &#125; if timediv(12345*1000000000+54321, 1000000000, &amp;e) != 12345 || e != 54321 &#123; throw("bad timediv") &#125; var z uint32 z = 1 if !atomic.Cas(&amp;z, 1, 2) &#123; throw("cas1") &#125; if z != 2 &#123; throw("cas2") &#125; z = 4 if atomic.Cas(&amp;z, 5, 6) &#123; throw("cas3") &#125; if z != 4 &#123; throw("cas4") &#125; z = 0xffffffff if !atomic.Cas(&amp;z, 0xffffffff, 0xfffffffe) &#123; throw("cas5") &#125; if z != 0xfffffffe &#123; throw("cas6") &#125; m = [4]byte&#123;1, 1, 1, 1&#125; atomic.Or8(&amp;m[1], 0xf0) if m[0] != 1 || m[1] != 0xf1 || m[2] != 1 || m[3] != 1 &#123; throw("atomicor8") &#125; m = [4]byte&#123;0xff, 0xff, 0xff, 0xff&#125; atomic.And8(&amp;m[1], 0x1) if m[0] != 0xff || m[1] != 0x1 || m[2] != 0xff || m[3] != 0xff &#123; throw("atomicand8") &#125; *(*uint64)(unsafe.Pointer(&amp;j)) = ^uint64(0) if j == j &#123; throw("float64nan") &#125; if !(j != j) &#123; throw("float64nan1") &#125; *(*uint64)(unsafe.Pointer(&amp;j1)) = ^uint64(1) if j == j1 &#123; throw("float64nan2") &#125; if !(j != j1) &#123; throw("float64nan3") &#125; *(*uint32)(unsafe.Pointer(&amp;i)) = ^uint32(0) if i == i &#123; throw("float32nan") &#125; if i == i &#123; throw("float32nan1") &#125; *(*uint32)(unsafe.Pointer(&amp;i1)) = ^uint32(1) if i == i1 &#123; throw("float32nan2") &#125; if i == i1 &#123; throw("float32nan3") &#125; testAtomic64() if _FixedStack != round2(_FixedStack) &#123; throw("FixedStack is not power-of-2") &#125; if !checkASM() &#123; throw("assembly checks failed") &#125;&#125; runtime·args(go/src/runtime/runtime1.go) 123456// 设置参数func args(c int32, v **byte) &#123; argc = c argv = v sysargs(c, v)&#125; runtime·osinit(go/src/runtime/os_linux.go) 1234// 初始化os， 根据不同的平台也不一样func osinit() &#123; ncpu = getproccount()&#125; runtime.schedinit(go/src/runtime/proc.go) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// The bootstrap sequence is://// call osinit// call schedinit// make &amp; queue new G// call runtime·mstart//// The new G calls runtime·main.// 启动顺序// 调用 osinit// 调用 schedinit// make &amp; queue new G// 调用 runtime·mstart// 创建 G 的调用 runtime·main.//// 初始化sched, 核心部分func schedinit() &#123; // raceinit must be the first call to race detector. // In particular, it must be done before mallocinit below calls racemapshadow. // raceinit 是作为 race detector(探测器) ，必须是的首个调用，特别是：必须在 调用 mallocinit 函数之前，在 racemapshadow函数之后调用 // 获取当前 G _g_ := getg() if raceenabled &#123; _g_.racectx, raceprocctx0 = raceinit() &#125; // 最大系统线程数量（即 M），参考标准库 runtime/debug.SetMaxThreads sched.maxmcount = 10000 tracebackinit() // 初始化 traceback moduledataverify() // 模块数据验证，负责检查链接器符号，以确保所有结构体的正确性 stackinit() // 栈初始化，复用管理链表 mallocinit() // 内存分配器初始化 mcommoninit(_g_.m) // 初始化当前 M cpuinit() // must run before alginit // 必须在 alginit 之前运行 alginit() // maps must not be used before this call // maps 不能在此调用之前使用，从 CPU 指令集初始化散列算法 modulesinit() // provides activeModules // 模块链接，提供 activeModules typelinksinit() // uses maps, activeModules // 使用 maps, activeModules itabsinit() // uses activeModules // 初始化 interface table，使用 activeModules msigsave(_g_.m) // 设置signal mask initSigmask = _g_.m.sigmask goargs() // 初始化命令行用户参数 goenvs() // 初始化环境变量 parsedebugvars() // 初始化debug参数，处理 GODEBUG、GOTRACEBACK 调试相关的环境变量设置 gcinit() // gc初始化 // 网络的上次轮询时间 sched.lastpoll = uint64(nanotime()) // 设置procs， 根据cpu核数和环境变量GOMAXPROCS， 优先环境变量 procs := ncpu if n, ok := atoi32(gogetenv("GOMAXPROCS")); ok &amp;&amp; n &gt; 0 &#123; procs = n &#125; // 调整 P 的数量，这时所有 P 均为新建的 P，因此不能返回有本地任务的 P if procresize(procs) != nil &#123; throw("unknown runnable goroutine during bootstrap") &#125; // For cgocheck &gt; 1, we turn on the write barrier at all times // and check all pointer writes. We can't do this until after // procresize because the write barrier needs a P. // 对于 cgocheck&gt;1 ，我们始终打开 write barrier 并检查所有指针写。 我们要等到 procresize 后才能执行此操作，因为写障碍需要一个P。 if debug.cgocheck &gt; 1 &#123; writeBarrier.cgo = true writeBarrier.enabled = true for _, p := range allp &#123; p.wbBuf.reset() &#125; &#125; if buildVersion == "" &#123; // Condition should never trigger. This code just serves // to ensure runtime·buildVersion is kept in the resulting binary. // 该条件永远不会被触发，此处只是为了防止 buildVersion 被编译器优化移除掉。 buildVersion = "unknown" &#125;&#125; runtime.newproc(go/src/runtime/proc.go) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169// Create a new g running fn with siz bytes of arguments.// Put it on the queue of g's waiting to run.// The compiler turns a go statement into a call to this.// Cannot split the stack because it assumes that the arguments// are available sequentially after &amp;fn; they would not be// copied if a stack split occurred./go:nosplit// 创建 G 运行 fn , 参数大小为 siz 。把 G 放到等待队列。编译器会将 go 语句转化为该调用。// 这时不能将栈进行分段，因为它假设了参数在 &amp;fn 之后顺序有效；如果 stack 进行了分段则他们不无法被拷贝。func newproc(siz int32, fn *funcval) &#123; // add 是一个指针运算，跳过函数指针，把栈上的参数起始地址找到，见 runtime2.go 中的 funcval 类型 argp := add(unsafe.Pointer(&amp;fn), sys.PtrSize) gp := getg() // 获取调用方 PC 寄存器值 pc := getcallerpc() // 用 g0 系统栈创建 goroutine 对象。传递的参数包括 fn 函数入口地址, argp 参数起始地址, siz 参数长度, gp(g0)，调用方 pc(goroutine) systemstack(func() &#123; newproc1(fn, (*uint8)(argp), siz, gp, pc) &#125;)&#125;// Create a new g running fn with narg bytes of arguments starting// at argp. callerpc is the address of the go statement that created// this. The new g is put on the queue of g's waiting to run.// 创建一个运行 fn 的新 g，具有 narg 字节大小的参数，从 argp 开始。callerps 是 go 语句的起始地址。新创建的 g 会被放入 g 的队列中等待运行。func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) &#123; // 因为是在系统栈运行所以此时的 g 为 g0 _g_ := getg() // 判断下 func 的实现是否为空 if fn == nil &#123; _g_.m.throwing = -1 // do not dump full stacks throw("go of nil func value") &#125; // 设置 g 对应的 m 的 locks++, 禁止抢占，因为它可以在一个局部变量中保存 p _g_.m.locks++ // disable preemption because it can be holding p in a local var siz := narg siz = (siz + 7) &amp;^ 7 // 字节对齐 // We could allocate a larger initial stack if necessary. // Not worth it: this is almost always an error. // 4*sizeof(uintreg): extra space added below // sizeof(uintreg): caller's LR (arm) or return address (x86, in gostartcall). // 必要时，可以分配并初始化一个更大的栈。 // 不值得：这几乎总是一个错误。 // 4*sizeof(uintreg): 在下方增加的额外空间 // sizeof(uintreg): 调用者 LR (arm) 返回的地址 (x86 在 gostartcall 中) if siz &gt;= _StackMin-4*sys.RegSize-sys.RegSize &#123; throw("newproc: function arguments too large for new goroutine") &#125; // 获取 p _p_ := _g_.m.p.ptr() // 从 g 空闲列表中，根据 p 获得一个新的 g newg := gfget(_p_) // 初始化阶段，gfget 是不可能找到 g 的，也可能运行中本来就已经耗尽了 if newg == nil &#123; // 创建一个拥有 _StackMin 大小的栈的 g newg = malg(_StackMin) // 将新创建的 g 从 _Gidle 更新为 _Gdead 状态 casgstatus(newg, _Gidle, _Gdead) // 将 Gdead 状态的 g 添加到 allg，这样 GC 不会扫描未初始化的栈 allgadd(newg) // publishes with a g-&gt;status of Gdead so GC scanner doesn't look at uninitialized stack. &#125; // 检查新 g 的执行栈 if newg.stack.hi == 0 &#123; throw("newproc1: newg missing stack") &#125; // 无论是取到的 g 还是新创建的 g，都应该是 _Gdead 状态 if readgstatus(newg) != _Gdead &#123; throw("newproc1: new g is not Gdead") &#125; // 计算运行空间大小，与 spAlign 对齐 totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize // extra space in case of reads slightly beyond frame totalSize += -totalSize &amp; (sys.SpAlign - 1) // align to spAlign // 确定 sp 和参数入栈位置 sp := newg.stack.hi - totalSize spArg := sp // arm if usesLR &#123; // caller's LR // 调用方的 LR 寄存器 *(*uintptr)(unsafe.Pointer(sp)) = 0 prepGoExitFrame(sp) spArg += sys.MinFrameSize &#125; // 处理参数，当有参数时，将参数拷贝到 goroutine 的执行栈中 if narg &gt; 0 &#123; // 从 argp 参数开始的位置，复制 narg 个字节到 spArg（参数拷贝） memmove(unsafe.Pointer(spArg), unsafe.Pointer(argp), uintptr(narg)) // This is a stack-to-stack copy. If write barriers // are enabled and the source stack is grey (the // destination is always black), then perform a // barrier copy. We do this *after* the memmove // because the destination stack may have garbage on // it. // 栈到栈的拷贝。如果启用了 write barrier 并且 源栈为灰色（目标始终为黑色），则执行 barrier 拷贝。因为目标栈上可能有垃圾，我们在 memmove 之后执行此操作。 // 如果需要 write barrier 并且 gc scan 未结束， if writeBarrier.needed &amp;&amp; !_g_.m.curg.gcscandone &#123; f := findfunc(fn.fn) stkmap := (*stackmap)(funcdata(f, _FUNCDATA_ArgsPointerMaps)) if stkmap.nbit &gt; 0 &#123; // We're in the prologue, so it's always stack map index 0. // 我们正位于 prologue (序言) 部分，因此栈 map 索引总是 0 bv := stackmapdata(stkmap, 0) // bulkBarrierBitmap执行写入障碍 bulkBarrierBitmap(spArg, spArg, uintptr(bv.n)*sys.PtrSize, 0, bv.bytedata) &#125; &#125; &#125; // 清理、创建并初始化的 g 的运行现场 memclrNoHeapPointers(unsafe.Pointer(&amp;newg.sched), unsafe.Sizeof(newg.sched)) newg.sched.sp = sp newg.stktopsp = sp newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function // +PCQuantum 从而前一个指令还在相同的函数内 newg.sched.g = guintptr(unsafe.Pointer(newg)) gostartcallfn(&amp;newg.sched, fn) // 初始化 g 的基本状态 newg.gopc = callerpc newg.ancestors = saveAncestors(callergp) // 调试相关，追踪调用方 newg.startpc = fn.fn // 如果 PC if _g_.m.curg != nil &#123; // 设置 profiler 标签 newg.labels = _g_.m.curg.labels &#125; // 统计 sched.ngsys if isSystemGoroutine(newg, false) &#123; atomic.Xadd(&amp;sched.ngsys, +1) &#125; newg.gcscanvalid = false // 将 g 更换为 _Grunnable 状态 casgstatus(newg, _Gdead, _Grunnable) // 分配 goid if _p_.goidcache == _p_.goidcacheend &#123; // Sched.goidgen is the last allocated id, // this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch]. // At startup sched.goidgen=0, so main goroutine receives goid=1. // Sched.goidgen 为最后一个分配的 id，这一批必须为 [sched.goidgen+1, sched.goidgen+GoidCacheBatch]。启动时 sched.goidgen=0, 因此主 goroutine 的 goid 为 1 // 一次分配多个 _GoidCacheBatch(16) 个ID _p_.goidcache = atomic.Xadd64(&amp;sched.goidgen, _GoidCacheBatch) _p_.goidcache -= _GoidCacheBatch - 1 _p_.goidcacheend = _p_.goidcache + _GoidCacheBatch &#125; newg.goid = int64(_p_.goidcache) _p_.goidcache++ if raceenabled &#123; newg.racectx = racegostart(callerpc) &#125; // trace 相关 if trace.enabled &#123; traceGoCreate(newg, newg.startpc) &#125; // 将这里新创建的 g 放入 p 的本地队列或直接放入全局队列，true 表示放入执行队列的下一个，false 表示放入队尾 runqput(_p_, newg, true) // 如果有空闲的 P、且 spinning 的 M 数量为 0，且主 goroutine 已经开始运行，则进行唤醒 p 。初始化阶段 mainStarted 为 false，所以 p 不会被唤醒 if atomic.Load(&amp;sched.npidle) != 0 &amp;&amp; atomic.Load(&amp;sched.nmspinning) == 0 &amp;&amp; mainStarted &#123; wakep() &#125; _g_.m.locks-- if _g_.m.locks == 0 &amp;&amp; _g_.preempt &#123; // restore the preemption request in case we've cleared it in newstack // 在 newstack 中清除了抢占请求的情况下恢复抢占请求 _g_.stackguard0 = stackPreempt &#125;&#125; runtime.mstart(go/src/runtime/proc.go) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// Called to start an M.//// This must not split the stack because we may not even have stack// bounds set up yet.//// May run during STW (because it doesn't have a P yet), so write// barriers are not allowed.// 启动 M ， M 的入口函数// 该函数不允许分段栈，因为我们甚至还没有设置栈的边界。它可能会在 STW 阶段运行（因为它还没有 P），所以 write barrier 也是不允许的///go:nosplit/go:nowritebarrierrecfunc mstart() &#123; _g_ := getg() // 确定执行栈的边界。通过检查 g 执行占的边界来确定是否为系统栈 osStack := _g_.stack.lo == 0 if osStack &#123; // Initialize stack bounds from system stack. // Cgo may have left stack size in stack.hi. // minit may update the stack bounds. // 根据系统栈初始化执行栈的边界。cgo 可能会离开 stack.hi 。minit 可能会更新栈的边界 size := _g_.stack.hi if size == 0 &#123; size = 8192 * sys.StackGuardMultiplier &#125; _g_.stack.hi = uintptr(noescape(unsafe.Pointer(&amp;size))) _g_.stack.lo = _g_.stack.hi - size + 1024 &#125; // Initialize stack guards so that we can start calling // both Go and C functions with stack growth prologues. // 初始化堆栈守卫，以便我们可以使用堆栈增长 prologue (序言) 开始调用Go和C函数。 _g_.stackguard0 = _g_.stack.lo + _StackGuard _g_.stackguard1 = _g_.stackguard0 // 启动 M mstart1() // Exit this thread. // 退出线程 if GOOS == "windows" || GOOS == "solaris" || GOOS == "plan9" || GOOS == "darwin" || GOOS == "aix" &#123; // Window, Solaris, Darwin, AIX and Plan 9 always system-allocate // the stack, but put it in _g_.stack before mstart, // so the logic above hasn't set osStack yet. // Window，Solaris，Darwin，AIX和Plan 9始终对栈进行系统分配，但将其放在mstart之前的_g_.stack中，因此上述逻辑尚未设置osStack。 osStack = true &#125; // 退出线程 mexit(osStack)&#125;func mstart1() &#123; _g_ := getg() // 检查当前执行的 g 是不是 g0 if _g_ != _g_.m.g0 &#123; throw("bad runtime·mstart") &#125; // Record the caller for use as the top of stack in mcall and // for terminating the thread. // We're never coming back to mstart1 after we call schedule, // so other calls can reuse the current frame. // 这里会记录前一个调用者的状态， 包含 PC , SP 以及其他信息。这份记录会当作最初栈 (top stack)，给之后的 mcall 调用，也用来结束那个线程。 // 接下來在 mstart1 调用到 schedule 之后就再也不会回到这个地方了，所以其他调用可以重用当前帧。 // 借助编译器的帮助获取 PC 和 SP , 然后在 save 中更新当前 G 的 sched (type gobuf) 的一些成员， 保存调用者的 pc 和 sp ，让日后其他执行者执行 gogo 函数的时候使用。 save(getcallerpc(), getcallersp()) asminit() // 初始化汇编，但是 amd64 架构下不需要执行任何代码就立刻返回，其他像是 arm、386 才有一些需在这里设定一些 CPU 相关的內容。 minit() // 初始化m 包括信号栈和信号掩码，procid // Install signal handlers; after minit so that minit can // prepare the thread to be able to handle the signals. // 设置信号 handler ；在 minit 之后，因为 minit 可以准备处理信号的的线程 if _g_.m == &amp;m0 &#123; // 在当前的 goroutine 的所属执行者是 m0 的情況下进入 mstartm0 函数，正式启动在此之前的 signal 处理设定，其中最关键的是 initsig 函数。 mstartm0() &#125; // 执行启动函数 if fn := _g_.m.mstartfn; fn != nil &#123; fn() &#125; // 如果当前 m 并非 m0，则要求绑定 p if _g_.m != &amp;m0 &#123; acquirep(_g_.m.nextp.ptr()) _g_.m.nextp = 0 &#125; // 彻底准备好，开始调度，永不返回 schedule()&#125; runtime·abort(go/src/runtime/stubs.go) 12345678// abort crashes the runtime in situations where even throw might not// work. In general it should do something a debugger will recognize// (e.g., an INT3 on x86). A crash in abort is recognized by the// signal handler, which will attempt to tear down the runtime// immediately.// 在抛出异常甚至都不起作用的情况下，abort会使运行时崩溃。通常，它应该执行调试程序可以识别的操作（例如，x86上的INT3）。// 信号处理程序会识别中止中的崩溃，这将尝试立即中断运行时。 INT 3func abort() 在汇编中实现（go/src/runtime/asm_amd64.s） 1234TEXT runtime·abort(SB),NOSPLIT,$0-0 INT $3loop: JMP loop 查看断点情况&emsp;&emsp;等运行完后， 查看断点情况如下： 123456789101112131415161718192021(gdb) i bNum Type Disp Enb Address What1 breakpoint keep y 0x0000000000452890 in _rt0_amd64_linux at go/src/runtime/rt0_linux_amd64.s:8 breakpoint already hit 1 time2 breakpoint keep y 0x000000000044ef70 in _rt0_amd64 at go/src/runtime/asm_amd64.s:15 breakpoint already hit 1 time3 breakpoint keep y 0x000000000044ef80 in runtime.rt0_go at go/src/runtime/asm_amd64.s:89 breakpoint already hit 1 time4 breakpoint keep y 0x0000000000436750 in runtime.check at go/src/runtime/runtime1.go:136 breakpoint already hit 1 time5 breakpoint keep y 0x00000000004361f0 in runtime.args at go/src/runtime/runtime1.go:60 breakpoint already hit 1 time6 breakpoint keep y 0x00000000004264a0 in runtime.osinit at go/src/runtime/os_linux.go:277 breakpoint already hit 1 time7 breakpoint keep y 0x000000000042a8b0 in runtime.schedinit at go/src/runtime/proc.go:526 breakpoint already hit 1 time8 breakpoint keep y 0x00000000004310b0 in runtime.newproc at go/src/runtime/proc.go:3239 breakpoint already hit 4 times9 breakpoint keep y 0x000000000042c4a0 in runtime.mstart at go/src/runtime/proc.go:1153 breakpoint already hit 5 times10 breakpoint keep y 0x0000000000450a60 in runtime.abort at go/src/runtime/asm_amd64.s:837]]></content>
      <categories>
        <category>【golang源码分析】</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【golang源码分析】之源码结构]]></title>
    <url>%2F2019%2F09%2F05%2F%E3%80%90golang%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%E4%B9%8B%E6%BA%90%E7%A0%81%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[为什么要看golang源码&emsp;&emsp;如果是为了简简单单的使用golang， 也许我们不需要去看golang源码。但是， 如果真的想在这方便有更深入的了解, 还是有必要去研究部分源码， 去深入了解原理， 这样在以后的编码中能够做到更高效； 另外，品读研习源码也能够很好的熟悉golang语法， 学习优质的代码编写。 注释项目地址&emsp;&emsp;注释源码见： cache2go-annotated 环境 系统： Linux amd64 Go: 1.12.9 代码统计&emsp;&emsp;通过工具统计代码如下： github.com/AlDanial/cloc v 1.74 T=26.59 s (272.7 files/s, 80119.3 lines/s) ----------------------------------------------------------------------------------- Language files blank comment code ----------------------------------------------------------------------------------- Go 6422 154211 230199 1538978 Assembly 538 11929 17475 100852 HTML 50 6499 331 46892 C 108 1216 1095 7910 Perl 15 355 369 2258 JSON 12 0 0 2061 Bourne Shell 13 155 645 1089 Markdown 13 271 0 825 Bourne Again Shell 26 192 307 802 XML 4 85 9 623 JavaScript 5 101 153 612 Python 1 130 101 358 C/C++ Header 20 76 193 275 DOS Batch 5 52 1 241 Protocol Buffers 1 1 0 196 CSS 3 51 9 176 Windows Resource File 4 22 0 134 RobotFramework 1 0 0 106 make 8 12 10 44 Fortran 90 2 1 3 8 C++ 1 3 5 7 awk 1 1 6 7 ----------------------------------------------------------------------------------- SUM: 7253 175363 250911 1704454 -----------------------------------------------------------------------------------&emsp;&emsp;看起来代码有170w行，无从下手。但其没必要对每一个模块都去研习，也不需要逐行去研习。只需要去研习关键的模块，了解概念、结构、流程以及代码组织等等。 这样算下来， 其实代码量也不多。 源码目录结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950.├── api # Go的api检查器 (go tool api)├── doc # GoHTML格式的官方文档和说明├── lib #├── misc #├── src # 源码│ ├── archive # 归档， 实现了tar/zip│ ├── bufio # 缓存IO│ ├── builtin # go内置预定义│ ├── bytes # 实现了用于操作 []byte 的函数│ ├── cmd # go 各种工具│ ├── compress # 压缩／解压，实现了：bzip2、flate、gzip、lzw、zlib│ ├── container # 容器数据结构，实现了: heap、list、ring│ ├── context # Goroutine上下文│ ├── crypto # 加密解密算法，实现了：aes、des、hmac、md5、rand、rsa、sha1、sha256、sha512等│ ├── database # 提供了各种SQL或类SQL数据库的通用API│ ├── debug # Go程序调试│ ├── encoding # 编码，实现了：ascii85、asn1、base32、base64、binary、csv、gob、hex、json、pem、xml│ ├── errors # 生成错误的函数， errors.New(text string)│ ├── expvar # 公共变量包（添加变量，可以监控），通过http在/debug/vars显示，包含命令行和内存信息│ ├── flag # 处理命令参数│ ├── fmt # 格式化│ ├── go # go│ ├── hash # hash算法，实现了adler32、crc32、crc64、fnv│ ├── html # template 实现了数据驱动的模板，用于生成可对抗代码注入的安全HTML输出│ ├── image # 2D图形│ ├── index # suffixarray 后缀数组：使用内存后缀数组实现子串搜索│ ├── internal # 内部包│ ├── io # I/O 原语提供基本接口│ ├── log # 日志│ ├── math # 基本的常量和数学函数│ ├── mime # 实现了MIME规范的一部分│ ├── net # 网络I/O，包括TCP/IP，UDP，域名解析和Unix域套接字， http, mail, rpc, smtp, url 等│ ├── os # 提供平台无关的OS接口│ ├── path # 实现了针对操作斜线分割路径的实用例程│ ├── plugin # 实现 Go 插件的加载和符号解析│ ├── reflect # 实现运行时反射│ ├── regexp # 正则表达式│ ├── runtime # 包含与 Go 的运行时系统交互的操作│ ├── sort # 排序│ ├── strconv # 对基本数据类型的字符串表示的转换│ ├── strings # 实现简单的函数来操纵 UTF-8 编码的字符串│ ├── sync # 提供基本的同步原语│ ├── syscall # 系统调用│ ├── testing # 测试│ ├── text # 文本相关的接口│ ├── time # 时间│ ├── unicode # unicode实现│ └── unsafe # 包含绕过Go程序类型安全的操作└── test # Go语言自身代码的文件&emsp;&emsp;这里的源码目录结构，会跟着理解的深入而逐步更新。 给自己打气&emsp;&emsp;]]></content>
      <categories>
        <category>【golang源码分析】</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【cache2go源码分析】]]></title>
    <url>%2F2019%2F09%2F03%2F%E3%80%90cache2go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%2F</url>
    <content type="text"><![CDATA[cache2go是什么&emsp;&emsp;在github上面的介绍是：Concurrency-safe golang caching library with expiration capabilities.意思是： 具有过期功能并发安全的go语言缓存库。注释项目地址&emsp;&emsp;注释源码见： cache2go-annotated 目录结构123456789benchmark_test.gocache.gocacheitem.gocachetable.gocache_test.goerrors.goexamplesLICENSE.txtREADME.md 目录结构如上所示，主要功能实现源码文件为： cache.go, cacheitem.go, cachetable.go. 接下来一一说明。 源码注释 cacheitem.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145/** Simple caching library with expiration capabilities* Copyright (c) 2013-2017, Christian Muehlhaeuser &lt;muesli@gmail.com&gt;** For license see LICENSE.txt*/package cache2goimport ( "sync" "time")// CacheItem is an individual cache item// Parameter data contains the user-set value in the cache.// CacheItem是单个的缓存条目， 也就是一个key-value缓存数据type CacheItem struct &#123; // 读写锁，保证CacheItem同步访问 sync.RWMutex // The item's key. // key 可以是任意类型 key interface&#123;&#125; // The item's data. // data 可以是任意类型 data interface&#123;&#125; // How long will the item live in the cache when not being accessed/kept alive. // 不被访问后的保活时间 lifeSpan time.Duration // Creation timestamp. // 创建的时间 createdOn time.Time // Last access timestamp. // 最近一次访问时间，KeepAlive函数修改 accessedOn time.Time // How often the item was accessed. // 访问的次数，KeepAlive函数修改 accessCount int64 // Callback method triggered right before removing the item from the cache // 被移除时候的回调函数 aboutToExpire []func(key interface&#123;&#125;)&#125;// NewCacheItem returns a newly created CacheItem.// Parameter key is the item's cache-key.// Parameter lifeSpan determines after which time period without an access the item// will get removed from the cache.// Parameter data is the item's value.// 创建CacheItemfunc NewCacheItem(key interface&#123;&#125;, lifeSpan time.Duration, data interface&#123;&#125;) *CacheItem &#123; t := time.Now() return &amp;CacheItem&#123; key: key, lifeSpan: lifeSpan, createdOn: t, accessedOn: t, accessCount: 0, aboutToExpire: nil, data: data, &#125;&#125;// KeepAlive marks an item to be kept for another expireDuration period.// 重置过期时间， 需要加锁（下面类似的不再说）func (item *CacheItem) KeepAlive() &#123; item.Lock() defer item.Unlock() item.accessedOn = time.Now() item.accessCount++&#125;// LifeSpan returns this item's expiration duration.// 返回lifeSpan， 不需要加锁， 因为创建后就没有情况会修改此值（下面类似的不再说）func (item *CacheItem) LifeSpan() time.Duration &#123; // immutable return item.lifeSpan&#125;// AccessedOn returns when this item was last accessed.// 返回accessedOnfunc (item *CacheItem) AccessedOn() time.Time &#123; item.RLock() defer item.RUnlock() return item.accessedOn&#125;// CreatedOn returns when this item was added to the cache.// 返回createdOnfunc (item *CacheItem) CreatedOn() time.Time &#123; // immutable return item.createdOn&#125;// AccessCount returns how often this item has been accessed.// 返回accessCountfunc (item *CacheItem) AccessCount() int64 &#123; item.RLock() defer item.RUnlock() return item.accessCount&#125;// Key returns the key of this cached item.// 返回keyfunc (item *CacheItem) Key() interface&#123;&#125; &#123; // immutable return item.key&#125;// Data returns the value of this cached item.// 返回datafunc (item *CacheItem) Data() interface&#123;&#125; &#123; // immutable return item.data&#125;// SetAboutToExpireCallback configures a callback, which will be called right// before the item is about to be removed from the cache.// 设置被移除时候的回调函数func (item *CacheItem) SetAboutToExpireCallback(f func(interface&#123;&#125;)) &#123; if len(item.aboutToExpire) &gt; 0 &#123; item.RemoveAboutToExpireCallback() &#125; item.Lock() defer item.Unlock() item.aboutToExpire = append(item.aboutToExpire, f)&#125;// AddAboutToExpireCallback appends a new callback to the AboutToExpire queue// 添加被移除时候的回调函数func (item *CacheItem) AddAboutToExpireCallback(f func(interface&#123;&#125;)) &#123; item.Lock() defer item.Unlock() item.aboutToExpire = append(item.aboutToExpire, f)&#125;// RemoveAboutToExpireCallback empties the about to expire callback queue// 删除被移除时候的回调函数func (item *CacheItem) RemoveAboutToExpireCallback() &#123; item.Lock() defer item.Unlock() item.aboutToExpire = nil&#125; cachetable.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419/** Simple caching library with expiration capabilities* Copyright (c) 2013-2017, Christian Muehlhaeuser &lt;muesli@gmail.com&gt;** For license see LICENSE.txt*/package cache2goimport ( "log" "sort" "sync" "time")// CacheTable is a table within the cache// 缓存表，type CacheTable struct &#123; // 读写锁，保证CacheItem同步访问 sync.RWMutex // The table's name. // 缓存表名称 name string // All cached items. // 所有缓存的条目 items map[interface&#123;&#125;]*CacheItem // Timer responsible for triggering cleanup. // 负责触发清除操作的计时器 cleanupTimer *time.Timer // Current timer duration. // 触发清理清除操作的时间间隔 cleanupInterval time.Duration // The logger used for this table. // 日志 logger *log.Logger // Callback method triggered when trying to load a non-existing key. // 加载一个不存在的key时触发的回调函数 loadData func(key interface&#123;&#125;, args ...interface&#123;&#125;) *CacheItem // Callback method triggered when adding a new item to the cache. // 添加缓存条目时触发的回调函数 addedItem []func(item *CacheItem) // Callback method triggered before deleting an item from the cache. // 删除缓存条目时触发的回调函数 aboutToDeleteItem []func(item *CacheItem)&#125;// Count returns how many items are currently stored in the cache.// 返回缓存条目的数量func (table *CacheTable) Count() int &#123; table.RLock() defer table.RUnlock() return len(table.items)&#125;// Foreach all items// 遍历缓存条目func (table *CacheTable) Foreach(trans func(key interface&#123;&#125;, item *CacheItem)) &#123; table.RLock() defer table.RUnlock() for k, v := range table.items &#123; trans(k, v) &#125;&#125;// SetDataLoader configures a data-loader callback, which will be called when// trying to access a non-existing key. The key and 0...n additional arguments// are passed to the callback function.// 设置加载一个不存在的key时触发的回调函数func (table *CacheTable) SetDataLoader(f func(interface&#123;&#125;, ...interface&#123;&#125;) *CacheItem) &#123; table.Lock() defer table.Unlock() table.loadData = f&#125;// SetAddedItemCallback configures a callback, which will be called every time// a new item is added to the cache.// 设置添加缓存条目时触发的回调函数func (table *CacheTable) SetAddedItemCallback(f func(*CacheItem)) &#123; if len(table.addedItem) &gt; 0 &#123; table.RemoveAddedItemCallbacks() &#125; table.Lock() defer table.Unlock() table.addedItem = append(table.addedItem, f)&#125;//AddAddedItemCallback appends a new callback to the addedItem queue// 添加添加缓存条目时触发的回调函数func (table *CacheTable) AddAddedItemCallback(f func(*CacheItem)) &#123; table.Lock() defer table.Unlock() table.addedItem = append(table.addedItem, f)&#125;// RemoveAddedItemCallbacks empties the added item callback queue// 删除添加缓存条目时触发的回调函数func (table *CacheTable) RemoveAddedItemCallbacks() &#123; table.Lock() defer table.Unlock() table.addedItem = nil&#125;// SetAboutToDeleteItemCallback configures a callback, which will be called// every time an item is about to be removed from the cache.// 设置删除缓存条目时触发的回调函数func (table *CacheTable) SetAboutToDeleteItemCallback(f func(*CacheItem)) &#123; if len(table.aboutToDeleteItem) &gt; 0 &#123; table.RemoveAboutToDeleteItemCallback() &#125; table.Lock() defer table.Unlock() table.aboutToDeleteItem = append(table.aboutToDeleteItem, f)&#125;// AddAboutToDeleteItemCallback appends a new callback to the AboutToDeleteItem queue// 添加删除缓存条目时触发的回调函数func (table *CacheTable) AddAboutToDeleteItemCallback(f func(*CacheItem)) &#123; table.Lock() defer table.Unlock() table.aboutToDeleteItem = append(table.aboutToDeleteItem, f)&#125;// RemoveAboutToDeleteItemCallback empties the about to delete item callback queue// 删除删除缓存条目时触发的回调函数func (table *CacheTable) RemoveAboutToDeleteItemCallback() &#123; table.Lock() defer table.Unlock() table.aboutToDeleteItem = nil&#125;// SetLogger sets the logger to be used by this cache table.// 设置日志func (table *CacheTable) SetLogger(logger *log.Logger) &#123; table.Lock() defer table.Unlock() table.logger = logger&#125;// Expiration check loop, triggered by a self-adjusting timer.// 过期检查， 能自动调节间隔func (table *CacheTable) expirationCheck() &#123; table.Lock() // 计时器停止，后面调整间隔后启动 if table.cleanupTimer != nil &#123; table.cleanupTimer.Stop() &#125; if table.cleanupInterval &gt; 0 &#123; table.log("Expiration check triggered after", table.cleanupInterval, "for table", table.name) &#125; else &#123; table.log("Expiration check installed for table", table.name) &#125; // To be more accurate with timers, we would need to update 'now' on every // loop iteration. Not sure it's really efficient though. // 每次会更新 now := time.Now() // 最小时间间隔 smallestDuration := 0 * time.Second // 遍历所有的items查找最近一个将要过期的时间间隔 for key, item := range table.items &#123; // Cache values so we don't keep blocking the mutex. item.RLock() lifeSpan := item.lifeSpan accessedOn := item.accessedOn item.RUnlock() // 0 表示永远不过期 if lifeSpan == 0 &#123; continue &#125; // 已经过期了，删除 if now.Sub(accessedOn) &gt;= lifeSpan &#123; // Item has excessed its lifespan. table.deleteInternal(key) &#125; else &#123; // Find the item chronologically closest to its end-of-lifespan. // 更新smallestDuration， 获取最近一个将要过期的时间间隔 if smallestDuration == 0 || lifeSpan-now.Sub(accessedOn) &lt; smallestDuration &#123; smallestDuration = lifeSpan - now.Sub(accessedOn) &#125; &#125; &#125; // Setup the interval for the next cleanup run. // 设置cleanupInterval为最近将要过期的时间间隔 table.cleanupInterval = smallestDuration if smallestDuration &gt; 0 &#123; // 重新启动下一次的过期检测 table.cleanupTimer = time.AfterFunc(smallestDuration, func() &#123; go table.expirationCheck() &#125;) &#125; table.Unlock()&#125;// 内部添加函数， 代码重用， 调用这个方法之前需要加锁func (table *CacheTable) addInternal(item *CacheItem) &#123; // Careful: do not run this method unless the table-mutex is locked! // It will unlock it for the caller before running the callbacks and checks table.log("Adding item with key", item.key, "and lifespan of", item.lifeSpan, "to table", table.name) table.items[item.key] = item // Cache values so we don't keep blocking the mutex. expDur := table.cleanupInterval addedItem := table.addedItem table.Unlock() // Trigger callback after adding an item to cache. // 触发增加条数的回调函数 if addedItem != nil &#123; for _, callback := range addedItem &#123; callback(item) &#125; &#125; // If we haven't set up any expiration check timer or found a more imminent item. // 如果当前没有过期检测函数或者当前添加的比当前最短的过期时间还早过期，则更新过期检测 if item.lifeSpan &gt; 0 &amp;&amp; (expDur == 0 || item.lifeSpan &lt; expDur) &#123; table.expirationCheck() &#125;&#125;// Add adds a key/value pair to the cache.// Parameter key is the item's cache-key.// Parameter lifeSpan determines after which time period without an access the item// will get removed from the cache.// Parameter data is the item's value.// 添加缓存条目到缓存表中， addInternal会释放锁func (table *CacheTable) Add(key interface&#123;&#125;, lifeSpan time.Duration, data interface&#123;&#125;) *CacheItem &#123; item := NewCacheItem(key, lifeSpan, data) // Add item to cache. table.Lock() table.addInternal(item) return item&#125;// 内部删除函数， 代码重用， 调用这个方法之前需要加锁func (table *CacheTable) deleteInternal(key interface&#123;&#125;) (*CacheItem, error) &#123; r, ok := table.items[key] if !ok &#123; return nil, ErrKeyNotFound &#125; // Cache value so we don't keep blocking the mutex. aboutToDeleteItem := table.aboutToDeleteItem table.Unlock() // Trigger callbacks before deleting an item from cache. // 触发删除条数的回调函数 if aboutToDeleteItem != nil &#123; for _, callback := range aboutToDeleteItem &#123; callback(r) &#125; &#125; // 触发CacheItem过期删除的回调函数 r.RLock() defer r.RUnlock() if r.aboutToExpire != nil &#123; for _, callback := range r.aboutToExpire &#123; callback(key) &#125; &#125; table.Lock() table.log("Deleting item with key", key, "created on", r.createdOn, "and hit", r.accessCount, "times from table", table.name) delete(table.items, key) return r, nil&#125;// Delete an item from the cache.// 从缓存表中删除缓存条目， addInternal会释放锁func (table *CacheTable) Delete(key interface&#123;&#125;) (*CacheItem, error) &#123; table.Lock() defer table.Unlock() return table.deleteInternal(key)&#125;// Exists returns whether an item exists in the cache. Unlike the Value method// Exists neither tries to fetch data via the loadData callback nor does it// keep the item alive in the cache.// 是否存在某个keyfunc (table *CacheTable) Exists(key interface&#123;&#125;) bool &#123; table.RLock() defer table.RUnlock() _, ok := table.items[key] return ok&#125;// NotFoundAdd tests whether an item not found in the cache. Unlike the Exists// method this also adds data if they key could not be found.// 不存在才添加func (table *CacheTable) NotFoundAdd(key interface&#123;&#125;, lifeSpan time.Duration, data interface&#123;&#125;) bool &#123; table.Lock() if _, ok := table.items[key]; ok &#123; table.Unlock() return false &#125; item := NewCacheItem(key, lifeSpan, data) table.addInternal(item) return true&#125;// Value returns an item from the cache and marks it to be kept alive. You can// pass additional arguments to your DataLoader callback function.// 获取value, 会通过KeepAlive更新访问时间和访问次数func (table *CacheTable) Value(key interface&#123;&#125;, args ...interface&#123;&#125;) (*CacheItem, error) &#123; table.RLock() r, ok := table.items[key] loadData := table.loadData table.RUnlock() if ok &#123; // Update access counter and timestamp. r.KeepAlive() return r, nil &#125; // Item doesn't exist in cache. Try and fetch it with a data-loader. // 如果不存在，通过loadData获取 if loadData != nil &#123; item := loadData(key, args...) if item != nil &#123; table.Add(key, item.lifeSpan, item.data) return item, nil &#125; return nil, ErrKeyNotFoundOrLoadable &#125; return nil, ErrKeyNotFound&#125;// Flush deletes all items from this cache table.// 清除所有的缓存条目， 不会调用 缓存表的aboutToDeleteItem 和 缓存条目的aboutToExpirefunc (table *CacheTable) Flush() &#123; table.Lock() defer table.Unlock() table.log("Flushing table", table.name) table.items = make(map[interface&#123;&#125;]*CacheItem) table.cleanupInterval = 0 if table.cleanupTimer != nil &#123; table.cleanupTimer.Stop() &#125;&#125;// CacheItemPair maps key to access counter// 缓存条目对type CacheItemPair struct &#123; Key interface&#123;&#125; AccessCount int64&#125;// CacheItemPairList is a slice of CacheIemPairs that implements sort.// Interface to sort by AccessCount.// 缓存条目对切片type CacheItemPairList []CacheItemPair// qsort需要的一些函数， 根据访问次数排序func (p CacheItemPairList) Swap(i, j int) &#123; p[i], p[j] = p[j], p[i] &#125;func (p CacheItemPairList) Len() int &#123; return len(p) &#125;func (p CacheItemPairList) Less(i, j int) bool &#123; return p[i].AccessCount &gt; p[j].AccessCount &#125;// MostAccessed returns the most accessed items in this cache table// 获取访问最多的几个CacheItem， 最多访问count个func (table *CacheTable) MostAccessed(count int64) []*CacheItem &#123; table.RLock() defer table.RUnlock() p := make(CacheItemPairList, len(table.items)) i := 0 for k, v := range table.items &#123; p[i] = CacheItemPair&#123;k, v.accessCount&#125; i++ &#125; sort.Sort(p) var r []*CacheItem c := int64(0) for _, v := range p &#123; if c &gt;= count &#123; break &#125; item, ok := table.items[v.Key] if ok &#123; r = append(r, item) &#125; c++ &#125; return r&#125;// Internal logging method for convenience.// 内部日志打印func (table *CacheTable) log(v ...interface&#123;&#125;) &#123; if table.logger == nil &#123; return &#125; table.logger.Println(v...)&#125; cache.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** Simple caching library with expiration capabilities* Copyright (c) 2012, Radu Ioan Fericean* 2013-2017, Christian Muehlhaeuser &lt;muesli@gmail.com&gt;** For license see LICENSE.txt*/package cache2goimport ( "sync")var ( // 全局缓存表的Map, 支持多个缓存表 cache = make(map[string]*CacheTable) // cache的锁 mutex sync.RWMutex)// Cache returns the existing cache table with given name or creates a new one// if the table does not exist yet.// 创建缓存func Cache(table string) *CacheTable &#123; mutex.RLock() t, ok := cache[table] mutex.RUnlock() if !ok &#123; mutex.Lock() t, ok = cache[table] // Double check whether the table exists or not. if !ok &#123; t = &amp;CacheTable&#123; name: table, items: make(map[interface&#123;&#125;]*CacheItem), &#125; cache[table] = t &#125; mutex.Unlock() &#125; return t&#125;]]></content>
      <categories>
        <category>【cache2go源码分析】</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>源码分析</tag>
        <tag>cache2go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开篇]]></title>
    <url>%2F2019%2F09%2F03%2F%E5%BC%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[为什么现在开始写博客&emsp;&emsp;从毕业开始到现在, 平时工作中也经常会查找一些知识点, 有些记录了, 有些却没有记录, 慢慢的容易忘记, 以前的记录也容易丢失, 所以希望以后在这里记录下来。记录的过程也是巩固的过程, 同时也方便以后回顾。主要记录的是什么&emsp;&emsp;本博客主要记录一些IT技术, 也可能会记录一些生活。 我是谁&emsp;&emsp;一个奋斗在IT界的Coder 123456789101112131415161718 _ooOoo_ o8888888o 88" . "88 (| -_- |) O\ = /O ____/`---'\____ . ' \\| |// `. / \\||| : |||// \ / _||||| -:- |||||- \ | | \\\ - /// | | | \_| ''\---/'' | | \ .-\__ `-` ___/-. / ___`. .' /--.--\ `. . __ ."" '&lt; `.___\_&lt;|&gt;_/___.' &gt;'"". | | : `- \`.;`\ _ /`;.`/ - ` : | | \ \ `-. \_ __\ /__ _/ .-` / /======`-.____`-.___\_____/___.-`____.-'====== `=---=']]></content>
      <categories>
        <category>随记</category>
      </categories>
      <tags>
        <tag>随记</tag>
      </tags>
  </entry>
</search>
